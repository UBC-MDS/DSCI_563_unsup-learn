{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/563_lab_banner.png)\n",
    "\n",
    "# Lab 2: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a name=\"im\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from hashlib import sha1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Submission instructions <a name=\"si\"></a>\n",
    "rubric={mechanics}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment by following the instructions below:\n",
    "    \n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "- [Here](https://github.com/UBC-MDS/public/tree/master/rubric) you will find the description of each rubric used in MDS.\n",
    "- Make at least three commits in your lab's GitHub repository.    \n",
    "- Push the final .ipynb file with your solutions to your GitHub repository for this lab.        \n",
    "- Before submitting your lab, run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).     \n",
    "- Make sure to enroll to Gradescope via [Canvas](https://canvas.ubc.ca/courses/106525).\n",
    "- Upload the .ipynb file to Gradescope.\n",
    "- Make sure that your plots/output are rendered properly in Gradescope.    \n",
    "- If the .ipynb file is too big or doesn't render on Gradescope for some reason, also upload a pdf (preferably WebPDF) or html export of .ipynb file with your solutions so that TAs can view your submission on Gradescope. \n",
    "- The data you download for this lab <b>SHOULD NOT BE PUSHED TO YOUR REPOSITORY</b> (there is also a `.gitignore` in the repo to prevent this).\n",
    "- Include a clickable link to your GitHub repo for the lab just below this cell.\n",
    "</div>    \n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR REPO LINK GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Warm-up \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Dimensionality reduction notation \n",
    "rubric={accuracy}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Suppose you apply dimensionality reduction on a data matrix $X_{n \\times d}$ using a dimensionality reduction technique such as PCA with $k$ component, where \n",
    "\n",
    "- $n \\rightarrow $ number of examples \n",
    "- $d \\rightarrow $ number of features\n",
    "- $k \\rightarrow $ number of components         \n",
    "\n",
    "Based on the Principal Component Analysis (PCA) notation we saw in class, what would be the dimensions of each of the matrices `W`, `Z`, and `X_hat`? \n",
    "    \n",
    "- (A) $n \\times k$ \n",
    "- (B) $n \\times d$\n",
    "- (C) $k \\times d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the variables to either \"A\", \"B\", or \"C\" \n",
    "W_dim = ...\n",
    "Z_dim = ...\n",
    "X_hat_dim = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.2 Picking the number of components $k$\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "    \n",
    "If you want to reduce dimensionality, why is it not a good idea to pick the number of components $k$ (`n_components` in `sklearn`) which gives the lowest reconstruction error?     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 PCA by hand\n",
    "\n",
    "Suppose you train the standard PCA algorithm on an already centered data matrix `X` (not shown) and you get `Z` and `W` shown below.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[10, 10], [5, 2], [4, 3], [4, 3]])\n",
    "W = np.array([[0.5, 0.5, -0.5, -0.5], [0.7, 0.1, 0.7, 0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 \n",
    "rubric={accuracy}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. How many rows and columns would be there in the data matrix `X`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_3_1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_rows = ...\n",
    "X_cols = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 \n",
    "rubric={accuracy}\n",
    "\n",
    "**Your tasks:**\n",
    "    \n",
    "Fill in the blanks: \n",
    "\n",
    "- In this toy example, we are reducing dimensionality from **$d$** dimensions to **$p$** dimensions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_3_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original dimensions\n",
    "d = ...\n",
    "\n",
    "# reduced_dimensions\n",
    "p = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3\n",
    "rubric={accuracy}\n",
    "\n",
    "Find the low-dimensional representation of the already centered `X_new` below.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[1,1,1,1],[1,0,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_3_3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Z_new = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### 1.3.4\n",
    "rubric={reasoning}\n",
    "    \n",
    "The third and fourth rows of the transformed matrix `Z` and the original matrix `X` are identical in our toy example. Does this mean that for two arbitrary data points in a dataset if the lower dimensional representations are identical, the higher dimensional representations in the original space have to be identical? Briefly explain.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_3_4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Reconstruction error \n",
    "\n",
    "Let's get an intuition for reconstruction error on a toy dataset.\n",
    "\n",
    "The code below creates a toy dataset with a few outliers. The function `get_recon_error_df` calculates normalized reconstruction errors between the original and reconstructed data points. Run the code and answer the following questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "outliers = np.array([[4, -3], [2.8, -3], [-3, 3]])\n",
    "x1 = np.random.randn(100)\n",
    "x2 = x1 + np.random.randn(100) / 2\n",
    "X = np.stack([x1, x2]).T\n",
    "X_noise = np.vstack([X, outliers])\n",
    "X_noise_scaled = StandardScaler().fit_transform(X_noise)\n",
    "plt.scatter(X_noise_scaled[:, 0], X_noise_scaled[:, 1], edgecolors='black', c='xkcd:azure');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### 1.4.1\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**    \n",
    "\n",
    "1. Write a docstring for the function `get_recon_error_df` provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_4_1\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_recon_error_df(orig, recon):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    loss = np.sqrt(np.sum((orig - recon) ** 2, axis=1))\n",
    "    loss = (loss - np.min(loss)) / (np.max(loss) - np.min(loss))  # normalization\n",
    "    loss_df = pd.DataFrame(data=loss, columns=[\"recon_error\"])\n",
    "    return loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2\n",
    "rubric={accuracy}\n",
    "\n",
    "**Your tasks:**    \n",
    "\n",
    "1. Fit `PCA` with `n_components=1` on `X_noise_scaled` with `random_state=123` and store the returned dataframe in `recon_df` below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_4_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recon_df = ...\n",
    "recon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.4.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3\n",
    "rubric={accuracy}\n",
    "\n",
    "**Your tasks:**    \n",
    "\n",
    "1. The last 3 rows (rows from indices 100 to 102) in `X_noise_scaled` are outliers. Calculate the average reconstruction error for outliers vs. average reconstruction error for other data points (i.e., non-outliers). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_4_3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers_avg_recon_error = ...\n",
    "non_outliers_avg_recon_error = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.4.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Implementing PCA using SVD\n",
    "<hr>\n",
    "rubric={accuracy}\n",
    "\n",
    "In this exercise, you'll implement your own version of PCA using SVD. The class `MyPCA` below implements `init` and `fit` methods. \n",
    "\n",
    "**Your tasks:** \n",
    "    \n",
    "1. Complete the `get_components` method of the class which returns the learned components. \n",
    "2. Complete the `transform` method of the class which returns transformed `Z` given `X`. \n",
    "> *Before applying transformation, center the data by subtracting the mean.*\n",
    "3. Complete `reconstruct` method of the class which returns reconstructed `X_hat` given transformed `Z`.\n",
    "> *Do not forget to add the mean back after reconstruction.*\n",
    "4. Run your code and compare results of your PCA and `sklearn` PCA using the code below.  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyPCA:\n",
    "    \"\"\"\n",
    "    Solves the PCA problem min_Z,W (Z*W-X)^2 using SVD\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X, 0)\n",
    "        X = X - self.mean  # Centralize the data\n",
    "        U, S, Vt = np.linalg.svd(\n",
    "            X\n",
    "        )  # SVD to get singular values and principal components\n",
    "        self.W = Vt[: self.k, :]  # store only first k components in self.W\n",
    "\n",
    "        \n",
    "    def get_components(self):\n",
    "        \"\"\"\n",
    "        Returns principal components.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        np.ndarray: an array containing k principal components.\n",
    "        \"\"\"\n",
    "        ### Solution_2_1\n",
    "        ...\n",
    "\n",
    "        \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforms X to Z and return Z.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : np.ndarray\n",
    "            Data to be transformed\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        np.ndarray: transformed data\n",
    "        \"\"\"\n",
    "        ### Solution_2_2\n",
    "\n",
    "        ...\n",
    "\n",
    "        \n",
    "    def reconstruct(self, Z):\n",
    "        \"\"\"\n",
    "        Given transformed data Z, returns reconstructed X_hat.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        Z : np.ndarray\n",
    "            PCA transformed data\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        np.ndarray: X_hat which has dimensions of original X\n",
    "        \"\"\"\n",
    "        ### Solution_2_3\n",
    "\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=100, centers=3, n_features=20)  ## Generating toy data\n",
    "\n",
    "for i in range(1, X.shape[1] + 1):\n",
    "    print(\"PCA implementation with {} components: OK\".format((i)))\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(X)\n",
    "\n",
    "    mypca = MyPCA(k=i)\n",
    "    mypca.fit(X)\n",
    "\n",
    "    assert np.allclose(\n",
    "        np.abs(pca.components_), np.abs(mypca.get_components())\n",
    "    ), \"W values do not match\"\n",
    "\n",
    "    Z = pca.transform(X)\n",
    "    Z_prime = mypca.transform(X)\n",
    "\n",
    "    assert np.allclose(np.abs(Z), np.abs(Z_prime)), \"Z values do not match\"\n",
    "\n",
    "    X_hat = pca.inverse_transform(Z)\n",
    "    X_hat_prime = mypca.reconstruct(Z_prime)\n",
    "    assert np.allclose(\n",
    "        np.abs(X_hat), np.abs(X_hat_prime)\n",
    "    ), \"reconstructed X_hat values do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction on animal faces \n",
    "<hr>\n",
    "\n",
    "In the next few exercises, you'll explore dimensionality reduction on a subset of [Animal Faces dataset](https://www.kaggle.com/andrewmvd/animal-faces) from Kaggle. I have created a subset of this dataset and preprocessed it a bit. \n",
    "    \n",
    "**Your tasks:**    \n",
    "    \n",
    "- Download animal_faces.pkl from [here](https://github.ubc.ca/mds-2021-22/datasets/blob/master/data/animal_faces.pkl) and save it locally under the data folder in this lab's directory. \n",
    "- Run the code below to unpickle the data and to display the first few images.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "animals = pickle.load(open(\"data/animal_faces.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5), subplot_kw={\"xticks\": (), \"yticks\": ()})\n",
    "for image, ax in zip(animals, axes.ravel()):\n",
    "    ax.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's flatten the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_anims = animals.reshape(len(animals), -1)\n",
    "X_anims.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flattened representation of the data is of shape $1500 \\times 10000$; Each image is represented with 10,000 features, each feature representing a pixel from the image. Let's define `image_shape` variable which will be handy later when we want to display images. Use this flattened representation `X_anims` in the rest of the lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Dimensionality reduction with PCA\n",
    "<hr>\n",
    "\n",
    "In this exercise, you will explore dimensionality reduction on the animal faces dataset using PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.1 Choosing the number of components \n",
    "rubric={accuracy,reasoning}   \n",
    "\n",
    "First, let's pick the appropriate value for the number of components. Recall that PCA finds principal components such that the first principal component has the highest variance, the second component has the next highest variance and so on. One way to decide the value of number of principal components ($k$ or `n_components`) is based on the amount of variance explained with $k$ components. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using [scikit-learn's `PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) implementation and the following hyperparameter values, fit a PCA model, and plot $k$ (for $k=1, \\ldots, 300$) vs. the proportion of total variance explained by the first $k$ components. \n",
    "    - `n_components=300`\n",
    "    - `random_state=42`\n",
    "2. What range of values for $k$ (`n_components` in `scikit-learn`) seems reasonable based on this plot? Briefly explain.         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "_Note that scikit-learn's PCA does the data centering for you. **Do not scale the data in this exercise and the next exercises**._ \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3_1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.2 Applying PCA\n",
    "rubric={accuracy}   \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train a pca model with the number of components you chose in 3.1 and `random_state=42`.    \n",
    "2. Get $Z$ (the transformed data), $W$ (principal components), and $X_{hat}$ (reconstructions).     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Z = ...\n",
    "W = ...\n",
    "X_hat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Interpreting the components learned by PCA\n",
    "<hr>\n",
    "\n",
    "PCA is a linear transformation and we can visualize and interpret the principal components learned by PCA. In this exercise, you will attempt to manually inspect and interpret these components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4.1 Visualizing PCA components\n",
    "rubric={viz,reasoning}\n",
    "\n",
    "Principal component matrix returned by PCA ($W$ matrix) is of shape: number of components by number of features. So you can reshape each component and visualize it as an image (in our case $100 \\times 100$ image). \n",
    "\n",
    "**Your tasks:**\n",
    "1. Visualize the first 15 components as $100 \\times 100$ images in a grid of 3 rows and 5 columns.\n",
    "2. Observe the components and identify some possible semantic themes captured by at least four components of your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "_Feel free to use code from lecture notes with appropriate attributions._\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4_1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4.2 Plotting strong component images\n",
    "rubric={accuracy,reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Pick four principal components from 4.1 where you observed some clear semantic themes. For these principal components, extract and display a few example images where the component values are strong for these particular components. \n",
    "2. Briefly comment on your results. Do the example images agree with your interpretation from 4.1?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Hint: The function to extract and show strong component images is provided below.  \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strong_comp_images(X_anims, Z, W, compn=1, image_shape=(100,100)):\n",
    "    \"\"\"\n",
    "    Given transformed data Z, components W, and the component index compn, the function \n",
    "    extracts and shows the images from X_anims where the component compn is strongest.   \n",
    "\n",
    "    Parameters\n",
    "    ----\n",
    "    X_anims : numpy array \n",
    "        Input data\n",
    "        \n",
    "    Z : numpy array\n",
    "        Transformed data\n",
    "    \n",
    "    W : numpy array\n",
    "        Components found by dimensionality reduction\n",
    "\n",
    "    compn : int\n",
    "        component to examine\n",
    "\n",
    "    image_shape : tuple\n",
    "        shape of the input image\n",
    "    Returns\n",
    "    ----\n",
    "    None. Shows the images with strong value for the given component\n",
    "    \"\"\"    \n",
    "    inds = np.argsort(Z[:, compn])[::-1]    \n",
    "    fig, ax = plt.subplots(\n",
    "        1, 7, figsize=(12,4), subplot_kw={\"xticks\": (), \"yticks\": ()}\n",
    "    )    \n",
    "    ax[0].set_title(f\"Component {compn}\")\n",
    "    ax[0].imshow(W[compn].reshape(image_shape))\n",
    "    i = 1\n",
    "    for image in inds[:6]:\n",
    "        ax[i].set_title(image)\n",
    "        ax[i].imshow(X_anims[image].reshape(image_shape))\n",
    "        i+=1\n",
    "    fig.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4.3 Visualization of first two dimentions\n",
    "rubric={viz}    \n",
    "\n",
    "One of the use cases of PCA is visualization. It's not possible to visualize high dimensional data. That said, since the first couple of components of PCA usually capture a lot of information from the data, we can plot the first two dimensions to get an intuition about the patterns in the data. \n",
    "    \n",
    "**Your tasks:**       \n",
    "\n",
    "1. Make a scatterplot of the first two dimensions in the transformed data $Z$ (from 3.2).       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4_3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4.4 Image tiling \n",
    "rubric={accuracy,quality,reasoning}    \n",
    "\n",
    "In this exercise you will attempt to interpret the first two dimensions of the transformed data. One way to interpret these dimensions is as follows:\n",
    "- Create an $m \\times m$ grid which roughly spans scatterplot region from the previous exercise. For example, if `Z` is your transformed data, the following range of values will get you five points spanning the first dimension. \n",
    "```\n",
    "np.linspace(np.min(Z[:, 0]), np.max(Z[:, 0]), 5))\n",
    "```\n",
    "- Once you have representative points which span the first dimension, get the indices of the data points closest to these points. \n",
    "- Plot the images corresponding to these indices as a grid and observe whether you see any pattern as the first dimension increases (left to right of the grid) and as the second dimension increases (bottom to top of the grid). \n",
    "\n",
    "Let's try this out with $m=5$, i.e., a $5 \\times 5$ grid. \n",
    "    \n",
    "**Your tasks:**\n",
    "    \n",
    "1. Make a $5 \\times 5$ grid that roughly spans the scatterplot region from the previous exercise (but stays within it). For each point on that grid, select the animal face whose first two dimensions are closest to the grid point. Plot a $5 \\times 5$ tiling of these animal faces, corresponding to the $5 \\times 5$ grid using the `img_tiling` function below.     \n",
    "2. What happens to the images as the first dimension increases (i.e., go from left to right of the grid)? What about the second dimension? Briefly discuss your observations and try to label your axes based on your interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Hint: The function to make the $5 \\times 5$ tiling plot is provided below   \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_tiling(idx, size=10, image_shape=(100, 100)):\n",
    "    \"\"\"\n",
    "    Plots a 5x5 tiling of faces from bottom to top and left to right. \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    idx: the indexes of the faces to be plotted. This should be a 5x5 matrix, where each\n",
    "         elements is an index corresponding to the closest animal face of that grid point.\n",
    "         position 0,0 of idx corresponds to the bottom left position in the grid \n",
    "         position 0,4 of idx corresponds to the top left position\n",
    "         position 4,0 of idx corresponds to the bottom right position\n",
    "         position 4,4 of idx corresponds to the top right position\n",
    "\n",
    "    size: the desired size of the plot;\n",
    "    \"\"\"\n",
    "    idx = np.array(idx, dtype=\"int32\")  # Just making sure the indexes are int\n",
    "\n",
    "    plt.figure(figsize=(size, size))  # Creating the image with the desired size\n",
    "\n",
    "    tile_size = 5\n",
    "    # Ploting the 5x5 tiling\n",
    "    for i in range(tile_size):\n",
    "        for j in range(tile_size):\n",
    "            face = np.reshape(\n",
    "                animals[idx[i, j]], (image_shape)\n",
    "            )  # Obtain the closest face\n",
    "            plt.imshow(\n",
    "                face, extent=(i * 32, (i + 1) * 32, j * 32, (j + 1) * 32)\n",
    "            )  # Plot the closest animal face\n",
    "    plt.xlim((0, 160))\n",
    "    plt.ylim((0, 160))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4_3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Non-negative Matrix Factorization (NMF)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5.1 Dimensionality reduction with NMF\n",
    "rubric={accuracy}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out dimensionality reduction with [NMF](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) with `n_components=15` and `random_state=42` and create transformed data `Z_nmf`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5_1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5.2 NMF components \n",
    "rubric={accuracy}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Write code to display NMF components and show images corresponding to some of the interesting components using the function `plot_strong_comp_images` from 4.2.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5.3 Interpretation of NMF components\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Interpret at least 4 components of your choice and the corresponding images. In what scenarios would NMF be preferred over PCA? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5_3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Food for thought\n",
    "<hr>\n",
    "\n",
    "Each lab will have a few challenging questions. These are usually low-risk questions and will contribute to maximum 5% of the lab grade. The main purpose here is to challenge yourself, dig deeper in a particular area, and going beyond what we explicitly discussed in the class. When you start working on labs, attempt all other questions before moving to these challenging questions. If you are running out of time, please skip the challenging questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-game-on.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### (Challenging) 6.1 Reconstruction error for anomaly detection\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Write a paragraph on how PCA and reconstruction errors might be used for anomaly detection. \n",
    "2. Get reconstruction errors for images using the function `get_recon_error_df` from Exercise 1. Write code to display a few original and reconstructed image pairs, where the reconstruction error is very high and where it is very low.\n",
    "3. Are you able to find anomalous images based on reconstruction error. Briefly discuss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "You might want to look up robust PCA for additional information on this topic.    \n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_6.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### (Challenging) 6.2 Clustering animal faces   \n",
    "<hr>\n",
    "\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Reduce dimensionality of the data using PCA and explore clustering animal faces with KMeans or other clustering methods of your choice with this representation.  \n",
    "2. Comment on the clustering results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### (Challenging) 6.3 Latent Semantic Analysis (LSA)\n",
    "<hr>\n",
    "\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "- Extract topics from the recipe titles dataset we used in lab1 using LSA ([TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)). Show the topics and discuss your results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6_3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting your assignment, please make sure you have followed all the instructions in the Submission Instructions section at the top. \n",
    "\n",
    "Well done!! Have a wonderful weekend! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"img/eva-happy-caturday.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:563]",
   "language": "python",
   "name": "conda-env-563-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(W_dim.encode('utf8')).hexdigest() == '32096c2e0eff33d844ee6d675407ace18289357d', \"W_dim is incorrect\"\n>>> assert sha1(Z_dim.encode('utf8')).hexdigest() == '6dcd4ce23d88e2ee9568ba546c007c63d9131c1b', \"Z_dim is incorrect\"\n>>> assert sha1(X_hat_dim.encode('utf8')).hexdigest() == 'ae4f281df5a5d0ff3cad6371f76d5c29b6d953ec', \"X_hat_dim is incorrect\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.1": {
     "name": "q1.3.1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(X_rows).encode('utf8')).hexdigest() == '1b6453892473a467d07372d45eb05abc2031647a', \"Incorrect number of rows.\"\n>>> assert sha1(str(X_cols).encode('utf8')).hexdigest() == '1b6453892473a467d07372d45eb05abc2031647a', \"Incorrect number of columns.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.2": {
     "name": "q1.3.2",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(d).encode('utf8')).hexdigest() == '1b6453892473a467d07372d45eb05abc2031647a', \"Your answer is incorrect.\"\n",
         "failure_message": "Incorrect original dimensions",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert sha1(str(p).encode('utf8')).hexdigest() == 'da4b9237bacccdf19c0760cab7aec4a8359010b0', \"Your answer is incorrect.\"\n",
         "failure_message": "Incorrect reduced dimension",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.3": {
     "name": "q1.3.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(Z_new.shape).encode('utf8')).hexdigest() == 'a0975468caa87203bf270355e1a6c54c2f724db7', \"Your answer is incorrect.\"\n",
         "failure_message": "Z_new shape is incorrect.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert sha1(str(Z_new[0][0]).encode('utf8')).hexdigest() == '38f6d7875e3195bdaee448d2cb6917f3ae4994af', \"Your answer is incorrect.\"\n>>> assert sha1(str(Z_new[0][1]).encode('utf8')).hexdigest() == '4693695d02f6236c431a6589af6dfdef6aa7fa31', \"Your answer is incorrect.\"\n",
         "failure_message": "Incorrect elements in Z_new",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.4.2": {
     "name": "q1.4.2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(recon_df.shape[0]).encode('utf8')).hexdigest() == '934385f53d1bd0c1b8493e44d0dfd4c8e88a04bb', \"Your answer is incorrect.\"\n",
         "failure_message": "Incorrect number of rows",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert sha1(str(np.round(recon_df.iloc[0][0], 3)).encode('utf8')).hexdigest() == 'f48b8680bbd951f42a2f865d51e3e8eeaec7142b', \"Your answer is incorrect.\"\n",
         "failure_message": "Incorrect number of cols",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.4.3": {
     "name": "q1.4.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(np.round(outliers_avg_recon_error, 3)).encode('utf8')).hexdigest() == 'dec89deff3a3ecde32b11029fcf20550a8b6fec2', \"Your answer is incorrect.\"\n",
         "failure_message": "Average of reconstruction error of outliers is incorrect.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert sha1(str(np.round(non_outliers_avg_recon_error, 3)).encode('utf8')).hexdigest() == 'ff30105317e5aa2bcbbe271e4617e7e61d9c6859', \"Your answer is incorrect.\"\n",
         "failure_message": "Average of reconstruction error of non outliers is incorrect.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 8,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> def test_it():\n...     X, y = make_blobs(n_samples=200, centers=4, n_features=30, random_state=123)\n...     for i in range(1, X.shape[1] + 1):\n...         pca = PCA(n_components=i)\n...         pca.fit(X)\n...         mypca = MyPCA(k=i)\n...         mypca.fit(X)\n...         assert np.allclose(np.abs(pca.components_), np.abs(mypca.get_components())), \"W values do not match\"\n...         Z = pca.transform(X)\n...         Z_prime = mypca.transform(X)\n...         assert np.allclose(np.abs(Z), np.abs(Z_prime)), \"Z values do not match\"\n...         X_hat = pca.inverse_transform(Z)\n...         X_hat_prime = mypca.reconstruct(Z_prime)\n...         assert np.allclose(np.abs(X_hat), np.abs(X_hat_prime)), \"reconstructed X_hat values do not match\"\n...         \n>>> test_it()\n",
         "hidden": false,
         "locked": false,
         "success_message": "Good job!"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
