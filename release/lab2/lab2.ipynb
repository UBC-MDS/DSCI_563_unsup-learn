{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 563 - Unsupervised Learning\n",
    "\n",
    "# Lab 2: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "rubric={mechanics:2}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **Please add a link to your GitHub repository here: LINK TO YOUR  REPO**\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "- Make at least three commits in your lab's GitHub repository.\n",
    "- Push the final .ipynb file with your solutions to your GitHub repository for this lab.\n",
    "- Upload the .ipynb file to Gradescope.\n",
    "- If the .ipynb file is too big or doesn't render on Gradescope for some reason, also upload a pdf or html in addition to the .ipynb. \n",
    "- Make sure that your plots/output are rendered properly in Gradescope.\n",
    "\n",
    "> [Here](https://github.com/UBC-MDS/public/tree/master/rubric) you will find the description of each rubric used in MDS.\n",
    "\n",
    "> As usual, do not push the data to the repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a name=\"im\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Warm-up \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.1 Dimensionality reduction notation \n",
    "rubric={reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Based on the notation we saw in class, what does each of the following matrix stand for in the context of Principal Component Analysis (PCA): $X, W, Z, \\hat{X}$? What would be the shape of each of these matrices in terms of the variables below? \n",
    "    \n",
    "- $n \\rightarrow $ number of examples \n",
    "- $d \\rightarrow $ number of features\n",
    "- $k \\rightarrow $ number of components         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Picking the number of components $k$\n",
    "rubric={reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "    \n",
    "In PCA, why don't we pick the value for number of components $k$ (`n_components` in `sklearn`) which gives the lowest reconstruction error?     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_2\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 PCA by hand\n",
    "\n",
    "Suppose you train the standard PCA algorithm on an already centered dataset `X` (not shown) and you get `Z` and `W` shown below.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[10, 10], [5, 2], [4, 3], [4, 3]])\n",
    "W = np.array([[0.5, 0.5, -0.5, -0.5], [0.7, 0.1, 0.7, 0.1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 \n",
    "rubric={accuracy:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What would be the shape of the training data matrix `X`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_3_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 \n",
    "rubric={accuracy:1}\n",
    "\n",
    "**Your tasks:**\n",
    "    \n",
    "Fill in the blanks: \n",
    "- Here we are reducing dimensionality from **__** dimensions to **__** dimensions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_3_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Find the low-dimensional representation of the already centered `X_new` below.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[1, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_3_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4\n",
    "rubric={reasoning:1}\n",
    "    \n",
    "The third and fourth rows of the transformed matrix `Z` are identical. Does this mean that the third and fourth rows of the training data matrix `X` also have to be identical?     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_3_4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Reconstruction error \n",
    "rubric={accuracy:3,reasoning:2}\n",
    "\n",
    "\n",
    "Let's get an intuition for reconstruction error on a toy dataset.\n",
    "\n",
    "The code below creates a toy dataset with a few outliers. The function `get_recon_error_df` calculates normalized reconstruction errors between the original and reconstructed data points. Run the code and answer the following questions. \n",
    "\n",
    "**Your tasks:**    \n",
    "1. Write docstring for the function `get_recon_error_df`.\n",
    "2. Fit `PCA` with `n_components=1` on `X_noise_scaled` and examine the reconstruction errors for different examples. You can follow the steps below to get reconstruction errors. \n",
    "    - create transformed data `Z` and reconstructed data `X_hat`\n",
    "    - call `get_recon_error_df()` with `X_noise_scaled` and `X_hat`\n",
    "4. The last 3 rows (rows from indices 100 to 102) in `X_noise_scaled` are outliers. Do you see any striking difference between reconstruction error for outliers vs. reconstruction error for other data points (i.e., non-outliers)?      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "\n",
    "np.random.seed(42)\n",
    "outliers = np.array([[4, -3], [2.8, -3], [-3, 3]])\n",
    "x1 = np.random.randn(100)\n",
    "x2 = x1 + np.random.randn(100) / 2\n",
    "X = np.stack([x1, x2]).T\n",
    "X_noise = np.vstack([X, outliers])\n",
    "X_noise_scaled = StandardScaler().fit_transform(X_noise)\n",
    "mglearn.discrete_scatter(X_noise_scaled[:, 0], X_noise_scaled[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_4_1\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recon_error_df(orig, recon):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    loss = np.sqrt(np.sum((orig - recon) ** 2, axis=1))\n",
    "    loss = (loss - np.min(loss)) / (np.max(loss) - np.min(loss))  # normalization\n",
    "    loss_df = pd.DataFrame(data=loss, columns=[\"recon_error\"])\n",
    "    return loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_4_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_4_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 1.5 Reconstruction error for anomaly detection\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Write a paragraph on how you might use PCA and reconstruction errors for anomaly detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "You might want to look up robust PCA for additional information on this topic.    \n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1_5_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Implementing PCA using SVD\n",
    "<hr>\n",
    "rubric={accuracy:7}\n",
    "\n",
    "In this exercise, you'll implement your own version of PCA using SVD. The class `MyPCA` below implements `init` and `fit` methods. \n",
    "\n",
    "**Your tasks:** \n",
    "    \n",
    "1. Complete the `get_components` method of the class which returns the learned components. \n",
    "2. Complete the `transform` method of the class which returns transformed `Z` given `X`. \n",
    "> *Before applying transformation, center the data by subtracting the mean.*\n",
    "3. Complete `reconstruct` method of the class which returns reconstructed `X_hat` given transformed `Z`.\n",
    "> *Do not forget to add the mean back after reconstruction.*\n",
    "4. Run your code and compare results of your PCA and `sklearn` PCA using the code below.  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPCA:\n",
    "    \"\"\"\n",
    "    Solves the PCA problem min_Z,W (Z*W-X)^2 using SVD\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X, 0)\n",
    "        X = X - self.mean  # Centralize the data\n",
    "        U, S, V = np.linalg.svd(\n",
    "            X\n",
    "        )  # SVD to get singular values and principal components\n",
    "        self.W = V[: self.k, :]  # store only first k components in self.W\n",
    "\n",
    "    def get_components(self):\n",
    "        \"\"\"\n",
    "        Returns principal components.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        np.ndarray: an array containing k principal components.\n",
    "        \"\"\"\n",
    "        ### Solution_2_1\n",
    "        \n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforms X to Z and return Z.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : np.ndarray\n",
    "            Data to be transformed\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        np.ndarray: transformed data\n",
    "        \"\"\"\n",
    "        ### Solution_2_2\n",
    "\n",
    "        \n",
    "\n",
    "    def reconstruct(self, Z):\n",
    "        \"\"\"\n",
    "        Given transformed data Z, returns reconstructed X_hat.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        Z : np.ndarray\n",
    "            PCA transformed data\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        np.ndarray: X_hat which has dimensions of original X\n",
    "        \"\"\"\n",
    "        ### Solution_2_3\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare our implementation with `sklearn`'s PCA implementation on the toy dataset above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=100, centers=3, n_features=20)  ## Generating toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, X.shape[1] + 1):\n",
    "    print(\"PCA implementation with {} components: OK\".format((i)))\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(X)\n",
    "\n",
    "    mypca = MyPCA(k=i)\n",
    "    mypca.fit(X)\n",
    "\n",
    "    assert np.allclose(\n",
    "        np.abs(pca.components_), np.abs(mypca.get_components())\n",
    "    ), \"W values do not match\"\n",
    "\n",
    "    Z = pca.transform(X)\n",
    "    Z_prime = mypca.transform(X)\n",
    "\n",
    "    assert np.allclose(np.abs(Z), np.abs(Z_prime)), \"Z values do not match\"\n",
    "\n",
    "    X_hat = pca.inverse_transform(Z)\n",
    "    X_hat_prime = mypca.reconstruct(Z_prime)\n",
    "    assert np.allclose(\n",
    "        np.abs(X_hat), np.abs(X_hat_prime)\n",
    "    ), \"reconstructed X_hat values do not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction on animal faces \n",
    "<hr>\n",
    "In the next few exercises, you'll explore dimensionality reduction on a subset of [Animal Faces dataset](https://www.kaggle.com/andrewmvd/animal-faces) from Kaggle. I have created a subset of this dataset and preprocessed it a bit. \n",
    "    \n",
    "**Your tasks:**    \n",
    "    \n",
    "- Download animal_faces.pkl from [here](https://github.ubc.ca/mds-2021-22/datasets/blob/master/data/animal_faces.pkl) and save it locally under the lab directory. \n",
    "- Run the code below to unpickle the data and display first few images.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "animals = pickle.load(open(\"animal_faces.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5), subplot_kw={\"xticks\": (), \"yticks\": ()})\n",
    "for image, ax in zip(animals, axes.ravel()):\n",
    "    ax.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's flatten the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_anims = animals.reshape(len(animals), -1)\n",
    "X_anims.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flattened representation of the data is of shape $1500 \\times 10000$; Each image is represented with 10,000 pixel features. Let's define image_shape variable which will be handy later when we want to display images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Dimensionality reduction with PCA\n",
    "<hr>\n",
    "\n",
    "In this exercise, you will explore dimensionality reduction on the animal faces dataset using PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Choosing the number of components \n",
    "rubric={accuracy:3,reasoning:2}   \n",
    "\n",
    "First, let's pick the appropriate value for the number of components. Recall that PCA finds principal components such that the first principal component has the highest variance, the second component has the next highest variance and so on. We can decide the value of number of principal components ($k$ or `n_components`) based on the amount of variance explained with $k$ components. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using [scikit-learn's `PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) implementation and the following hyperparameter values, fit a PCA model, and plot $k$ (for $k=1,\\ldots, 300$) vs. the proportion of total variance explained by the first $k$ components. \n",
    "    - `n_components=300`\n",
    "    - `random_state=42`\n",
    "2. What range of values for $k$ (`n_components` in `scikit-learn`) seems reasonable based on this plot? Briefly explain.         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "_Note that scikit-learn's PCA does the data centering for you. **Do not scale the data in this exercise and the next exercises**._ \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3_1_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3_1_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data transformation\n",
    "rubric={accuracy:3}   \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train a pca model with the number of components you chose in 3.1 and `random_state=42`.    \n",
    "2. Get $Z$ (transformed data), $W$ (principal components), and $X_{hat}$ (reconstructions).     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3_2_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3_2_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Interpreting PCA components \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualizing PCA components\n",
    "rubric={viz:4,reasoning:2}\n",
    "\n",
    "Principal component matrix returned by PCA ($W$ matrix) is of shape number of components by number of features. So you can reshape each component and visualize it as an image (in our case $100 \\times 100$ image). \n",
    "\n",
    "**Your tasks:**\n",
    "1. Visualize the first 15 components as $100 \\times 100$ images in a grid of 3 rows and 5 columns.\n",
    "2. Observe the components and comment on the possible semantic themes captured by at least a couple of components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "_Feel free to use code from lecture notes with appropriate attributions._\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4_1_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4_2_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Plotting strong component images\n",
    "rubric={reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Pick 2 to 4 principal components from 4.1 where you observed some possible semantic themes. For these principal components, display a few example images with strong principal component values for those principal components. You can write your own code for this or use the function `plot_strong_comp_images`, which I am providing below. \n",
    "2. Briefly comment on your results. Do the example images agree with your semantic interpretation from 4.1?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strong_comp_images(Z, compn=1):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----\n",
    "    Z : numpy array\n",
    "        PCA Transformed data\n",
    "\n",
    "    compn : int\n",
    "        component to examine\n",
    "\n",
    "    Returns\n",
    "    ----\n",
    "    None\n",
    "    \"\"\"\n",
    "    inds = np.argsort(Z[:, compn])[::-1]\n",
    "    fig, axes = plt.subplots(\n",
    "        2, 5, figsize=(10, 5), subplot_kw={\"xticks\": (), \"yticks\": ()}\n",
    "    )\n",
    "    fig.suptitle(\"Large component %d\" % (compn))\n",
    "    for i, (ind, ax) in enumerate(zip(inds, axes.ravel())):\n",
    "        ax.imshow(X_anims[ind].reshape(image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4_2_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4_2_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 4.3 Reconstructions\n",
    "rubric={reasoning:1}   \n",
    "   \n",
    "**Your tasks:**\n",
    "        \n",
    "1. Get reconstruction errors for images using the function `get_recon_error_df` from Exercise 1. \n",
    "2. Write code to display a few original and reconstructed image pairs, where the reconstruction error is very high and where it is very low.\n",
    "3. Briefly comment on the reconstructions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4_3_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4_3_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4_3_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: More interpretation of PCA components\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Visualization\n",
    "rubric={viz:2}    \n",
    "\n",
    "One of the use cases of PCA is visualization. It's not possible to visualize high dimensional data. But since the first couple of components of PCA usually capture a lot of information from the data, we can plot PCA the first two components, for example, to get an intuition of the patterns in the data. \n",
    "    \n",
    "**Your tasks:**       \n",
    "\n",
    "1. Make a scatterplot of the first two dimensions in the transformed data $Z$ (from 3.1).       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5_1_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Image tiling \n",
    "rubric={accuracy:5,reasoning:3}    \n",
    "\n",
    "In this exercise you will attempt to interpret PCA components. One way to interpret the components is as follows:\n",
    "- Create a $m \\times m$ grid which roughly spans scatterplot region from the previous exercise. For example, if `Z` is your transformed data, the following range of values will get you five points spanning the first principal component. \n",
    "```\n",
    "np.linspace(np.min(Z[:, 0]), np.max(Z[:, 0]), 5))\n",
    "```\n",
    "- Once you have representative points which span the first principal component, get the indices of the data points closest to these points. \n",
    "- Plot the images corresponding to these indices as a grid and observe whether you see any pattern as the first principal component increases (left to right of the grid) and as the second principal component increases (bottom to top of the grid). \n",
    "\n",
    "Let's try this out with $m=5$, i.e., a $5 \\times 5$ grid. \n",
    "    \n",
    "**Your tasks:**\n",
    "    \n",
    "1. Make a $5 \\times 5$ grid that roughly spans the scatterplot region from the previous exercise (but stays within it). For each point on that grid, select the animal face whose first two principal components are closest to the grid point. Plot a $5 \\times 5$ tiling of these animal faces, corresponding to the $5 \\times 5$ principal component grid using the `img_tiling` function below. \n",
    "    \n",
    "2. What happens to the images as the first principal component increases (i.e., go from left to right of the grid)? What about the second principal component?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Hint: The function to make the $5 \\times 5$ tiling plot is provided below   \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_tiling(idx, size=10, image_shape=(100, 100)):\n",
    "    \"\"\"\n",
    "    Plots a 5x5 tiling of faces.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    idx: the indexes of the faces to be plotted. This should be a 5x5 matrix, where each\n",
    "         elements is an index corresponding to the closest animal face of that grid point.\n",
    "\n",
    "    size: the desired size of the plot;\n",
    "    \"\"\"\n",
    "    idx = np.array(idx, dtype=\"int32\")  # Just making sure the indexes are int\n",
    "\n",
    "    plt.figure(figsize=(size, size))  # Creating the image with the desired size\n",
    "\n",
    "    tile_size = 5\n",
    "    # Ploting the 5x5 tiling\n",
    "    for i in range(tile_size):\n",
    "        for j in range(tile_size):\n",
    "            face = np.reshape(\n",
    "                animals[idx[i, j]], (image_shape)\n",
    "            )  # Obtain the closest face\n",
    "            plt.imshow(\n",
    "                face, extent=(i * 32, (i + 1) * 32, j * 32, (j + 1) * 32)\n",
    "            )  # Plot the closest animal face\n",
    "\n",
    "    plt.xlim((0, 160))\n",
    "    plt.ylim((0, 160))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5_2_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Non-negative Matrix Factorization (NMF)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Dimensionality reduction with NMF\n",
    "rubric={accuracy:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out dimensionality reduction with [NMF](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) with `n_components=15` and `random_state=42` and create transformed data `Z_nmf`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6_1_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Examining NMF components \n",
    "rubric={accuracy:3,reasoning:3}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Write code to display NMF components and show images corresponding to some of the interesting components using the function `plot_strong_comp_images` from 4.2.  \n",
    "2. Compare the components and representative images with the ones you got with PCA in Exercises 4.1 and 4.2. Briefly discuss your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6_2_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6_2_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Exercise 7: Clustering animal faces   \n",
    "<hr>\n",
    "\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Reduce dimensionality of the data using PCA with `n_components=15` and `random_state=123` and \n",
    "explore clustering animal faces with KMeans or other clustering methods of your choice.  \n",
    "2. Comment on the clustering results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_7_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_7_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLEASE READ BEFORE YOU SUBMIT:** \n",
    "\n",
    "When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from \"1\" will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Push all your work to your GitHub lab repository. \n",
    "4. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "5. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done!! Have a great weekend! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"eva-happy-caturday.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:563]",
   "language": "python",
   "name": "conda-env-563-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
