{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/563_banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 7: Recommender Systems Part I\n",
    "\n",
    "UBC Master of Data Science program, 2023-24\n",
    "\n",
    "Instructor: Varada Kolhatkar\n",
    "\n",
    "> People who agreed in the past are likely to agree again in future. <br>\n",
    "-- [The Master Algorithm](https://www.amazon.ca/Master-Algorithm-Ultimate-Learning-Machine-ebook/dp/B012271YB2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture plan, imports, and LOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Lecture plan  \n",
    " \n",
    "- Motivation (~10 mins)\n",
    "- Formulating the recommendation problem (~10 mins)\n",
    "- Evaluation and baseline approaches (~10 mins)\n",
    "- Questions for class discussion (~5 mins)\n",
    "- Break (~5 mins) \n",
    "- Collaborative filtering (~20 mins)\n",
    "- Class demo (~10 mins)\n",
    "- Questions for class discussion (~5 mins)\n",
    "- Summary and conclusion (~5 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Learning outcomes <a name=\"lo\"></a>\n",
    "\n",
    "From this lecture, students are expected to be able to:\n",
    "- State the problem of recommender systems. \n",
    "- Describe components of a utility matrix. \n",
    "- Create a utility matrix given ratings data. \n",
    "- Describe a common approach to evaluate recommender systems. \n",
    "- Implement some baseline approaches to complete the utility matrix. \n",
    "- Explain the idea of collaborative filtering. \n",
    "- Describe how you can use a PCA-like model to fill in the utility matrix. \n",
    "- Explain how to interpret $Z$ and $W$ in the context of recommendation systems. \n",
    "- Explain how the loss function of collaborative filtering differs from the loss function of regular PCA. \n",
    "- Learn to be mindful of some serious consequences of recommendation systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ❓❓ Questions for you\n",
    "**iClicker cloud join link: https://join.iclicker.com/NGJD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of watch time on YouTube do you think comes from recommendations?\n",
    "- (A) 50%\n",
    "- (B) 60%\n",
    "- (C) 20%\n",
    "- (D) 90%\n",
    "\n",
    "This question is based on [this source](https://developers.google.com/machine-learning/recommendation/overview). The statistics might have changed now. \n",
    "\n",
    "<br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Recommender systems intro and motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.1 What is a recommender system?\n",
    "\n",
    "- A recommender or a recommendation system **recommends** a particular product or service to users they are likely to consume. \n",
    "\n",
    "![](img/recommendation_system.png)\n",
    "<!-- <img src=\"img/recommendation_system.png\" alt=\"\" height=\"900\" width=\"900\">  -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Recommender Systems**\n",
    "\n",
    "- A user goes to Amazon to buy products. \n",
    "- Amazon has some information about the user. They also have information about other users buying similar products. \n",
    "- What should they recommend to the user, so that they buy more products? \n",
    "- There's no \"right\" answer (no label). \n",
    "- The whole idea is to understand user behavior in order to recommend them products they are likely to consume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.2 Why should we care about recommendation systems?\n",
    "\n",
    "- Almost everything we buy or consume today is in some way or the other influenced by recommendation systems. \n",
    "    - Music (Spotify), videos (YouTube), news, books and products (Amazon), movies (Netflix), jokes, restaurants, dating , friends (Facebook), professional connections (LinkedIn)\n",
    "- Recommendation systems are at the core of the success of many companies such as Amazon and [Netflix](https://help.netflix.com/en/node/100639).\n",
    "- As a result, we receive Capstone projects focused on developing recommender systems.\n",
    "    - A Past MDS Capstone: Present personalized journal article recommendations to health care professionals.\n",
    " \n",
    "![](img/reco-examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recommendation systems are often presented as powerful tools that significantly **reduce the effort users need to put in finding items**, effectively mitigating the problem of information overload.\n",
    "- This is more or less true in many contexts. Consider, for instance, the experience of shopping an umbrella on Amazon without the help of recommendations or any specific ranking of products.\n",
    "  \n",
    "- In the absence of a recommendation system, users would be faced with the daunting task of sifting through thousands of available products to find the one that best suits their needs.\n",
    "\n",
    "![](img/info-overload.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That said, we should always be mindful of the drawbacks of relying heavily on recommender systems.\n",
    "  \n",
    "- For example, these systems tend to recommend articles and products that are similar to those a user has previously interacted with or those their friends like.\n",
    "  \n",
    "- While this can improve user experience by presenting more of what the system predicts the user will like, it can also lead to a phenomenon known as **\"filter bubbles\"**.\n",
    "- This effect **narrows a user's exposure to diverse viewpoints and information**. Such a narrowing of perspective can be detrimental, particularly in the context of scientific research or political discourse, where exposure to a wide range of perspectives is crucial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3 Data and main approaches\n",
    "\n",
    "**What kind of data we need to build recommendation systems?**\n",
    "\n",
    "- Customer purchase history data (We worked with it last week.)\n",
    "- **User-item interactions** (e.g., ratings or clicks) (most common)\n",
    "- **Features related to items or users** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Main approaches**\n",
    "\n",
    "- **Collaborative filtering (today's focus)**\n",
    "    - \"Unsupervised\" learning \n",
    "    - We only have labels $y_{ij}$ (rating of user $i$ for item $j$). \n",
    "    - We learn latent features.  \n",
    "- Content-based recommenders \n",
    "    - Supervised learning\n",
    "    - Extract features $x_i$ of users and/or items building a model to predict rating $y_i$ given $x_i$. \n",
    "    - Apply model to predict for new users/items. \n",
    "- Hybrid \n",
    "    - Combining collaborative filtering with content-based filtering\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Recommender systems problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1 Problem formulation\n",
    "\n",
    "- Most often the data for recommender systems come in as **interactions** between a set of items and a set of users. \n",
    "- We have two entities: $N$ **users** and $M$ **items**. \n",
    "- **Users** are consumers. \n",
    "- **Items** are the products or services offered.  \n",
    "    - E.g., movies (Netflix), books (Amazon), songs (spotify), people (tinder)      \n",
    "- A **utility matrix** is the matrix that captures **interactions** between $N$ **users** and $M$ **items**. \n",
    "- The interaction may come in different forms: \n",
    "    - ratings, clicks, purchases\n",
    "- Below is a toy utility matrix. Here $N$ = 6 and $M$ = 5.  \n",
    "- Each entry $y_{ij}$ ($i^{th}$ row and $j^{th}$ column) denotes the rating given by the user $i$ to item $j$. \n",
    "- We represent users in terms of items and items in terms of users.     \n",
    "\n",
    "![](img/utility_matrix.png)\n",
    "<!-- <img src=\"img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\">  -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The utility matrix is very sparse because usually users only interact with a few items. \n",
    "- For example: \n",
    "    - all Netflix users will have rated only a small percentage of content available on Netflix\n",
    "    - all amazon clients will have rated only a small fraction of items among all items available on Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**What do we predict?**\n",
    "\n",
    "Given a utility matrix of $N$ users and $M$ items, **complete the utility matrix**. In other words, **predict missing values in the matrix**. \n",
    "\n",
    "![](img/utility_matrix.png)\n",
    "<!-- <img src=\"img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\">  -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once we have predicted ratings, we can recommend items to users they are likely to rate higher.\n",
    "- Note: rating prediction $\\neq$ Classification or regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**In classification or regression:**\n",
    "- We have $X$ and targets for some rows in $X$. \n",
    "- We want to predict the last column (target column).  \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**In rating prediction**\n",
    "\n",
    "- Ratings data has many missing values in the utility matrix. There is no special target column. We want to predict the missing entries in the matrix. \n",
    "- Since our goal is to **predict** ratings, usually the utility matrix is referred to as $Y$ matrix. \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "? & ? & \\checkmark  & ? & \\checkmark\\\\\n",
    "\\checkmark & ? & ?  & ? & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\\\\\n",
    "? & ? & ?  & ? & ?\\\\\n",
    "? & ? & ? & \\checkmark & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating utility matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work with the following toy example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam</td>\n",
       "      <td>Lion King</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sam</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sam</td>\n",
       "      <td>The Little Mermaid</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sam</td>\n",
       "      <td>Bambi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam</td>\n",
       "      <td>The Social Dilemma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eva</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eva</td>\n",
       "      <td>The Social Dilemma</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Eva</td>\n",
       "      <td>Man on Wire</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat</td>\n",
       "      <td>The Little Mermaid</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pat</td>\n",
       "      <td>Lion King</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pat</td>\n",
       "      <td>Bambi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jim</td>\n",
       "      <td>The Social Dilemma</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jim</td>\n",
       "      <td>Malcolm x</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jim</td>\n",
       "      <td>Man on Wire</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id            movie_id  rating\n",
       "0   Sam     Lion King           5     \n",
       "1   Sam     Toy Story           4     \n",
       "2   Sam     The Little Mermaid  5     \n",
       "3   Sam     Bambi               5     \n",
       "4   Sam     The Social Dilemma  1     \n",
       "5   Eva     Toy Story           1     \n",
       "6   Eva     The Social Dilemma  5     \n",
       "7   Eva     Man on Wire         5     \n",
       "8   Pat     The Little Mermaid  4     \n",
       "9   Pat     Lion King           5     \n",
       "10  Pat     Bambi               5     \n",
       "11  Jim     The Social Dilemma  5     \n",
       "12  Jim     Malcolm x           4     \n",
       "13  Jim     Man on Wire         5     "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_ratings = pd.read_csv(\"data/toy-movie-ratings.csv\")\n",
    "toy_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_key = \"user_id\"\n",
    "item_key = \"movie_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 14\n",
      "Average rating:  4.214\n",
      "Number of users (N): 4\n",
      "Number of items (M): 7\n",
      "Fraction non-nan ratings: 0.500\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ratings, item_key=\"movie_id\", user_key=\"user_id\"):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"Average rating:  %0.3f\" % (np.mean(ratings[\"rating\"])))\n",
    "    N = len(np.unique(ratings[user_key]))\n",
    "    M = len(np.unique(ratings[item_key]))\n",
    "    print(\"Number of users (N): %d\" % N)\n",
    "    print(\"Number of items (M): %d\" % M)\n",
    "    print(\"Fraction non-nan ratings: %0.3f\" % (len(ratings) / (N * M)))\n",
    "    return N, M\n",
    "\n",
    "\n",
    "N, M = get_stats(toy_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's construct utility matrix with `number of users` rows and `number of items` columns from the ratings data. \n",
    "> Note we are constructing a non-sparse matrix for demonstration purpose here. In real life it's recommended that you work with sparse matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(toy_ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(toy_ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(toy_ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(toy_ratings[item_key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why do we need all these mappers? \n",
    "    - We want to store the rating for user $i$ and item $j$ at $Y[i,j]$ location in the utility matrix. \n",
    "    - So we define `user_mapper` and `item_mapper` which map user and item ids to indices. \n",
    "    - Once we have predicted ratings for users and items, we want to be able to map it to the original user and item ids so that we recommend the right product to the right user. \n",
    "    - So we have `user_inverse_mapper` and `item_inverse_mapper` which map indices to original user and item ids.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def create_Y_from_ratings(\n",
    "    data, N, M, user_mapper, item_mapper, user_key=\"user_id\", item_key=\"movie_id\"\n",
    "):  # Function to create a dense utility matrix\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mat = create_Y_from_ratings(toy_ratings, N, M, user_mapper, item_mapper)\n",
    "Y_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0 NaN  NaN  NaN   5.0 NaN   5.0  1.0\n",
       "1 NaN  NaN   4.0  5.0 NaN   5.0 NaN \n",
       "2  5.0  5.0 NaN  NaN   4.0 NaN  NaN \n",
       "3  5.0  5.0 NaN  NaN   5.0  1.0  4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Rows represent users.\n",
    "- Columns represent items (movies in our case).\n",
    "- Each cell gives the rating given by the user to the corresponding movie. \n",
    "- Users are features for movies and movies are features for users.\n",
    "- Our goal is to predict missing entries in the utility matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3 Evaluation\n",
    "\n",
    "- We'll try a number of methods to fill in the missing entries in the utility matrix.\n",
    "- Although there is no notion of \"accurate\" recommendations, we need a way to evaluate our predictions so that we'll be able to compare different methods.\n",
    "- Although we are doing unsupervised learning, we'll split the data and evaluate our predictions as follows.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data splitting**\n",
    "\n",
    "- We split the ratings into train and validation sets. \n",
    "- It's easier to split the ratings data instead of splitting the utility matrix.\n",
    "- Don't worry about `y`; we're not really going to use it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 3), (3, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = toy_ratings.copy()\n",
    "y = toy_ratings[user_key]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we will create utility matrices for train and validation splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_mat = create_Y_from_ratings(X_train, N, M, user_mapper, item_mapper)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M, user_mapper, item_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 7), (4, 7))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat.shape, valid_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39285714285714285"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(X_train) / (N * M)) # Fraction of non-nan entries in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10714285714285714"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(X_valid) / (N * M)) # Fraction of non-nan entries in the valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1    2    3    4    5    6\n",
       "0 NaN  NaN NaN   5.0 NaN   5.0  1.0\n",
       "1 NaN  NaN  4.0  5.0 NaN  NaN  NaN \n",
       "2  5.0 NaN NaN  NaN   4.0 NaN  NaN \n",
       "3  5.0 NaN NaN  NaN   5.0  1.0  4.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1   2   3   4    5   6\n",
       "0 NaN NaN  NaN NaN NaN NaN  NaN\n",
       "1 NaN NaN  NaN NaN NaN  5.0 NaN\n",
       "2 NaN  5.0 NaN NaN NaN NaN  NaN\n",
       "3 NaN  5.0 NaN NaN NaN NaN  NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(valid_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train_mat` has only ratings from the train set and `valid_mat` has only ratings from the valid set.\n",
    "- During training we assume that we do not have access to some of the available ratings. We predict these ratings and evaluate them against ratings in the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Questions for you**\n",
    "\n",
    "- How do train and validation utility matrices differ? \n",
    "- Why are utility matrices for train and validation sets are of the same shape?\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Now that we have train and validation sets, how do we evaluate our predictions?\n",
    "- You can calculate the error between actual ratings and predicted ratings with metrics of your choice. \n",
    "    - Most common ones are MSE or RMSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The `error` function below calculates RMSE and `evaluate` function prints train and validation RMSE.\n",
    "- Lower RMSE $\\rightarrow$ predicted ratings are closer to the actual ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X1, X2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((X1 - X2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_X, train_X, valid_X, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_X, train_X)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_X, valid_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Baseline Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's first try some simple approaches to predict missing entries. \n",
    "\n",
    "1. Global average baseline\n",
    "2. Per-user average baseline\n",
    "3. Per-item average baseline\n",
    "4. Average of 2 and 3\n",
    "    - Take an average of per-user and per-item averages. \n",
    "5. [$k$-Nearest Neighbours imputation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)    \n",
    "    \n",
    "I'll show you 1. and 5. You'll explore 2., 3., and 4. in the lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1 Global average baseline\n",
    "\n",
    "- Let's examine RMSE of the global average baseline. \n",
    "- In this baseline we predict everything as the global average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  4.0  4.0  4.0  4.0  4.0  4.0  4.0\n",
       "1  4.0  4.0  4.0  4.0  4.0  4.0  4.0\n",
       "2  4.0  4.0  4.0  4.0  4.0  4.0  4.0\n",
       "3  4.0  4.0  4.0  4.0  4.0  4.0  4.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "pd.DataFrame(pred_g).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 1.48\n",
      "Global average valid RMSE: 1.00\n"
     ]
    }
   ],
   "source": [
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2 [$k$-nearest neighbours imputation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)\n",
    "\n",
    "- Can we try $k$-nearest neighbours type imputation? \n",
    "- Impute missing values using the mean value from $k$ nearest neighbours found in the training set. \n",
    "- Calculate distances between examples using features where neither value is missing. \n",
    "\n",
    "![](img/utility_matrix.png)\n",
    "<!-- <img src=\"img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\">  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1    2    3    4    5    6\n",
       "0 NaN  NaN NaN   5.0 NaN   5.0  1.0\n",
       "1 NaN  NaN  4.0  5.0 NaN  NaN  NaN \n",
       "2  5.0 NaN NaN  NaN   4.0 NaN  NaN \n",
       "3  5.0 NaN NaN  NaN   5.0  1.0  4.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2, keep_empty_features=True)\n",
    "train_mat_imp = imputer.fit_transform(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  5.0  0.0  4.0  5.0  4.5  5.0  1.0\n",
       "1  5.0  0.0  4.0  5.0  4.5  3.0  2.5\n",
       "2  5.0  0.0  4.0  5.0  4.0  3.0  2.5\n",
       "3  5.0  0.0  4.0  5.0  5.0  1.0  4.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_mat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN imputer train RMSE: 0.00\n",
      "KNN imputer valid RMSE: 4.24\n"
     ]
    }
   ],
   "source": [
    "evaluate(train_mat_imp, train_mat, valid_mat, model_name=\"KNN imputer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- We can look at the nearest neighbours of a query item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  5.0  0.0  4.0  5.0  4.5  5.0  1.0\n",
       "1  5.0  0.0  4.0  5.0  4.5  3.0  2.5\n",
       "2  5.0  0.0  4.0  5.0  4.0  3.0  2.5\n",
       "3  5.0  0.0  4.0  5.0  5.0  1.0  4.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_mat_imp).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question**\n",
    "- Instead of imputation, what would be the consequences if we replace `NaN` with zeros so that we can calculate distances between vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once you have predictions, you can sort them based on ratings and recommend items with highest ratings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ❓❓ Questions for you\n",
    "**iClicker cloud join link: https://join.iclicker.com/NGJD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 7.1 Select all of the following statements which are **True** (iClicker)\n",
    "\n",
    "- (A) In the context of recommendation systems, the shapes of validation utility matrix and train utility matrix are the same. \n",
    "- (B) RMSE perfectly captures what we want to measure in the context of recommendation systems. \n",
    "- (C) It would be reasonable to impute missing values in the utility matrix by taking the average of the ratings given to an item by similar users.  \n",
    "- (D) In KNN type imputation, if a user has not rated any items yet, a reasonable strategy would be recommending them the most popular item. \n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} V's Solutions!\n",
    ":class: tip, dropdown\n",
    "- A, C, D\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for class discussion\n",
    "\n",
    "For each of the following methods, discuss how it might be applied to the problem of item recommendation:\n",
    "\n",
    "1. Clustering\n",
    "> V's answer: If you cluster items, you could recommend other items in the same cluster when someone looks at a particular item. You could also try clustering users and recommending items to a user based on users in the same cluster.\n",
    "\n",
    "2. Graphs and breadth-first search\n",
    "> V's answer: You could make a graph where two items are connected if they share a user in common (e.g. a user that bought both, or reviewed both, or some other criterion). Then if you run BFS starting from that node, you'd explore similar items -- from most similar to least similar because it's breadth-first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- One of the most popular approach for recommendation systems. \n",
    "- Approach used by the winning entry (and most of the entries) in the Netflix competition. \n",
    "- An unsupervised approach\n",
    "    - Only uses the user-item interactions given in the ratings matrix. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Netflix prize**\n",
    "\n",
    "![](img/netflix-prize.png)\n",
    "\n",
    "[Source](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- 100M ratings from ~0.5M users on ~18k movies.\n",
    "- Grand prize was \\$1M for the first team to reduce squared error at least by 10%.\n",
    "- Winning entry (and most entries) used collaborative filtering:\n",
    "- A simple collaborative filtering method that does really well:\n",
    "   - \"Regularized matrix factorization\". Now adopted by many companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Intuition\n",
    "- **People who agreed in the past are likely to agree again in future.** \n",
    "- We may have similar users and similar items which can help us predict missing entries. \n",
    "- Leverage social information to provide recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Given a utility matrix with many missing entries, how can we predict missing ratings?  \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "? & ? & \\checkmark  & ? & \\checkmark\\\\\n",
    "\\checkmark & ? & ?  & ? & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\\\\\n",
    "? & ? & ?  & ? & ?\\\\\n",
    "? & ? & ? & \\checkmark & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Can we use something like PCA?**\n",
    "- We are not exactly interested in individual ratings or clicks. We want to find users with similar tastes. \n",
    "- So we want to learn some latent features related to typical users and typical items. \n",
    "- We have used PCA/LSA to extract meaningful features before. \n",
    "- Can we use the same idea here? Yes! \n",
    "- Collaborative filtering main idea\n",
    "    - Run **PCA-like** algorithm on the utility matrix to learn latent features related to typical users and typical items. \n",
    "    - Use **reconstructions** to fill in missing entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Toy movie recommendation example\n",
    "\n",
    "- Let's walk through a movie recommendation toy example. \n",
    "- The toy data below contains movie ratings for seven movies given by 4 users. \n",
    "- Do you see any pattern here?\n",
    "\n",
    "![](img/toy-movie.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this toy example, we see clear groups of movies and users.\n",
    "    - For movies: Children movies and documentaries \n",
    "    - For users: Children movie lovers and documentary lovers  \n",
    "- How can we identify such latent features?\n",
    "    - Can we use something similar to PCA or LSA (`TruncatedSVD`)? <br><br>\n",
    "![](img/toy-movie-pattern.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once we identify latent features with `TruncatedSVD` we can get $Z$ and $W$ and we can fill in the missing entries by reconstructing the matrix with the product $Z@W$. \n",
    "- $Z$ has embeddings or representations of users and $W$ has embeddings of items. \n",
    "- The rating prediction for a user-item pair is the dot product between the embedding of the user and embedding of the item.\n",
    "- With this approach it's possible to get some rating predictions which are smaller than zero or greater than 5.\n",
    "  \n",
    "![](img/toy-movie-pred.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam</td>\n",
       "      <td>Lion King</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sam</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sam</td>\n",
       "      <td>The Little Mermaid</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sam</td>\n",
       "      <td>Bambi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam</td>\n",
       "      <td>The Social Dilemma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eva</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eva</td>\n",
       "      <td>The Social Dilemma</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Eva</td>\n",
       "      <td>Man on Wire</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat</td>\n",
       "      <td>The Little Mermaid</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pat</td>\n",
       "      <td>Lion King</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pat</td>\n",
       "      <td>Bambi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jim</td>\n",
       "      <td>The Social Dilemma</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jim</td>\n",
       "      <td>Malcolm x</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jim</td>\n",
       "      <td>Man on Wire</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id            movie_id  rating\n",
       "0   Sam     Lion King           5     \n",
       "1   Sam     Toy Story           4     \n",
       "2   Sam     The Little Mermaid  5     \n",
       "3   Sam     Bambi               5     \n",
       "4   Sam     The Social Dilemma  1     \n",
       "5   Eva     Toy Story           1     \n",
       "6   Eva     The Social Dilemma  5     \n",
       "7   Eva     Man on Wire         5     \n",
       "8   Pat     The Little Mermaid  4     \n",
       "9   Pat     Lion King           5     \n",
       "10  Pat     Bambi               5     \n",
       "11  Jim     The Social Dilemma  5     \n",
       "12  Jim     Malcolm x           4     \n",
       "13  Jim     Man on Wire         5     "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the utility matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users (N)  : 4\n",
      "Number of movies (M) : 7\n"
     ]
    }
   ],
   "source": [
    "N_toy = len(np.unique(toy_ratings[\"user_id\"]))\n",
    "M_toy = len(np.unique(toy_ratings[\"movie_id\"]))\n",
    "print(f\"Number of users (N)  : {N_toy}\")\n",
    "print(f\"Number of movies (M) : {M_toy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper_toy = dict(zip(np.unique(toy_ratings[\"user_id\"]), list(range(N_toy))))\n",
    "item_mapper_toy = dict(zip(np.unique(toy_ratings[\"movie_id\"]), list(range(M_toy))))\n",
    "user_inverse_mapper_toy = dict(\n",
    "    zip(list(range(N_toy)), np.unique(toy_ratings[\"user_id\"]))\n",
    ")\n",
    "item_inverse_mapper_toy = dict(\n",
    "    zip(list(range(M_toy)), np.unique(toy_ratings[\"movie_id\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bambi</th>\n",
       "      <th>Lion King</th>\n",
       "      <th>Malcolm x</th>\n",
       "      <th>Man on Wire</th>\n",
       "      <th>The Little Mermaid</th>\n",
       "      <th>The Social Dilemma</th>\n",
       "      <th>Toy Story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eva</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jim</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pat</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bambi  Lion King  Malcolm x  Man on Wire  The Little Mermaid  \\\n",
       "Eva NaN    NaN        NaN         5.0         NaN                   \n",
       "Jim NaN    NaN         4.0        5.0         NaN                   \n",
       "Pat  5.0    5.0       NaN        NaN           4.0                  \n",
       "Sam  5.0    5.0       NaN        NaN           5.0                  \n",
       "\n",
       "     The Social Dilemma  Toy Story  \n",
       "Eva  5.0                 1.0        \n",
       "Jim  5.0                NaN         \n",
       "Pat NaN                 NaN         \n",
       "Sam  1.0                 4.0        "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_toy = create_Y_from_ratings(\n",
    "    toy_ratings, N_toy, M_toy, user_mapper_toy, item_mapper_toy, user_key=\"user_id\", item_key=\"movie_id\"\n",
    ")\n",
    "utility_mat_toy = pd.DataFrame(\n",
    "    Y_toy, columns=item_mapper_toy.keys(), index=user_mapper_toy.keys()\n",
    ")\n",
    "utility_mat_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "data_toy = utility_mat_toy.to_numpy()\n",
    "model_toy = TruncatedSVD(n_components=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_toy.fit(data_toy) # This won't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have missing data and we need to impute it to some numeric values so that we can train `TruncatedSVD` on it.  \n",
    "- How about replacing missing data with zeros? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_svd_toy = np.nan_to_num(data_toy)  # replace all nan values with zeros\n",
    "model_toy = TruncatedSVD(n_components=2, random_state=42)\n",
    "model_toy.fit(data_svd_toy);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's look at the transformed data $Z$. \n",
    "- $Z$ maps users to latent features of items.\n",
    "- Each row of $Z$ is a new representation of a user with latent features of items.\n",
    "- In our case the latent features of items can be named as **Children movies** and **Documentaries**.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Children movies??</th>\n",
       "      <th>Documentaries??</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eva</th>\n",
       "      <td>1.57</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jim</th>\n",
       "      <td>1.46</td>\n",
       "      <td>7.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pat</th>\n",
       "      <td>7.68</td>\n",
       "      <td>-1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>9.38</td>\n",
       "      <td>-0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Children movies??  Documentaries??\n",
       "Eva  1.57               6.64           \n",
       "Jim  1.46               7.77           \n",
       "Pat  7.68              -1.64           \n",
       "Sam  9.38              -0.98           "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_toy = model_toy.transform(data_svd_toy)\n",
    "Z_df = pd.DataFrame(\n",
    "    Z_toy, index=user_mapper_toy.keys(), columns=[\"Children movies??\", \"Documentaries??\"]\n",
    ")\n",
    "Z_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's look at $W$. \n",
    "- $W$ maps items to latent features of users.\n",
    "- Each column of $W$ is a new representation of an item with latent features of users. \n",
    "- In our case the latent features of users can be named as **Children movie lovers** and **Documentary lovers**.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_toy = model_toy.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bambi</th>\n",
       "      <th>Lion King</th>\n",
       "      <th>Malcolm x</th>\n",
       "      <th>Man on Wire</th>\n",
       "      <th>The Little Mermaid</th>\n",
       "      <th>The Social Dilemma</th>\n",
       "      <th>Toy Story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Children movie lovers??</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary lovers??</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Bambi  Lion King  Malcolm x  Man on Wire  \\\n",
       "Children movie lovers??  0.56   0.56       0.04       0.10          \n",
       "Documentary lovers??    -0.12  -0.12       0.29       0.67          \n",
       "\n",
       "                         The Little Mermaid  The Social Dilemma  Toy Story  \n",
       "Children movie lovers??  0.51                0.16                0.26       \n",
       "Documentary lovers??    -0.11                0.66                0.03       "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_df = pd.DataFrame(\n",
    "    W_toy,\n",
    "    columns=item_mapper_toy.keys(),\n",
    "    index=[\"Children movie lovers??\", \"Documentary lovers??\"],\n",
    ")\n",
    "W_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recommendation systems, items are features of users and users are features of items. So we can also think of $W$ as representation of each movie in terms of latent features of users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Children movie lovers??</th>\n",
       "      <th>Documentary lovers??</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bambi</th>\n",
       "      <td>0.562779</td>\n",
       "      <td>-0.121174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lion King</th>\n",
       "      <td>0.562779</td>\n",
       "      <td>-0.121174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malcolm x</th>\n",
       "      <td>0.038657</td>\n",
       "      <td>0.287367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Man on Wire</th>\n",
       "      <td>0.100051</td>\n",
       "      <td>0.666422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Little Mermaid</th>\n",
       "      <td>0.512129</td>\n",
       "      <td>-0.106044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Social Dilemma</th>\n",
       "      <td>0.161957</td>\n",
       "      <td>0.657316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toy Story</th>\n",
       "      <td>0.257970</td>\n",
       "      <td>0.025021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Children movie lovers??  Documentary lovers??\n",
       "Bambi               0.562779                -0.121174            \n",
       "Lion King           0.562779                -0.121174            \n",
       "Malcolm x           0.038657                 0.287367            \n",
       "Man on Wire         0.100051                 0.666422            \n",
       "The Little Mermaid  0.512129                -0.106044            \n",
       "The Social Dilemma  0.161957                 0.657316            \n",
       "Toy Story           0.257970                 0.025021            "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can get rating predictions if we get reconstructions by multiplying $Z$ and $W$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.97</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4.62</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.32</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>5.34</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.52</td>\n",
       "      <td>4.52</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6\n",
       "0  0.08  0.08  1.97  4.58  0.10  4.62  0.57\n",
       "1 -0.12 -0.12  2.29  5.32 -0.07  5.34  0.57\n",
       "2  4.52  4.52 -0.17 -0.32  4.10  0.17  1.94\n",
       "3  5.40  5.40  0.08  0.28  4.91  0.87  2.40"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Z_toy@W_toy).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.3 Interpretation of $Z$ and $W$ in collaborative filtering\n",
    "\n",
    "- Given a utility matrix $Y$ and a specified number of components $k$ (representing the number of latent features), PCA decomposes the utility matrix $Y$ into two matrices, $Z$ and $W$, as shown below. \n",
    "\n",
    "$$Y_{N \\times M} \\approx Z_{N \\times k} W_{k \\times M}$$ \n",
    "\n",
    "![](img/PCA-collab-filtering.png)\n",
    "<!-- <img src=\"img/PCA-collab-filtering.png\" alt=\"\" height=\"900\" width=\"900\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this context, although the mathematical model remains consistent, the interpretation of the output is quite different from traditional PCA applications. \n",
    "\n",
    "- In the traditional discussion about PCA, we distinguish clearly between features and examples. We view $Z$ as the matrix representing transformed features and $W$ as the matric of basis vectors that define the new feature space.\n",
    "- In the context of recommendation systems, the distinctions between examples and features becomes blurred.\n",
    "    - Users can be considered as features from the perspective of items, and vice versa, items can be considered as features from the perspective of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The matrix $Z$ effectively maps users to latent features of items, where:\n",
    "    - Each row in $Z$ represents a user profile in the context of latent item features.\n",
    "- Conversely, $W$ maps items to latent features of users, where:\n",
    "    - Each column in $W$ represents an item profile in the context of latent user features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Latent features for users** \n",
    "\n",
    "- In the original space, a user is represented based on their interactions across all items (e.g., movies) \n",
    "- In the new space, we represent them using the latent features extracted by PCA for items. \n",
    "- Each column of $Z$ corresponds to latent feature for **items**. \n",
    "- You can represent users as: \n",
    "    - User Eva = 90% documentaries fan + 10% children's movies fan\n",
    "    - User Pat = 80% children's movies fan + 20% documentaries fan\n",
    "\n",
    "![](img/PCA-collab-filtering.png)\n",
    "\n",
    "<!-- <img src=\"img/PCA-collab-filtering.png\" alt=\"\" height=\"600\" width=\"600\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Latent features for items**\n",
    "\n",
    "- In the original space, we represent an item in terms of all users. \n",
    "- In the new space, we represent them using the latent features extracted by PCA.\n",
    "- Each row of $W$ corresponds to specific latent features associated with **users**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- This is the overall intuition but there are a few things we need to be careful about.     \n",
    "    - When we used `TruncatedSVD` we replaced all missing entries with zeros. \n",
    "    - Is it a reasonable approach? What could be the problems with this approach?     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.4 Loss function of collaborative filtering\n",
    "\n",
    "Can we use the loss function of PCA for this?\n",
    "\n",
    "$$f(Z, W) = \\sum_{i=1}^{n} \\lVert{W^Tz_i - y_i}\\rVert^2_2 $$\n",
    "\n",
    "- $W^Tz_i \\rightarrow$ reconstructed rating \n",
    "- $y_i \\rightarrow$ original rating \n",
    "- Here, the problem with using conventional SVD is that \n",
    "    - We have many missing entries\n",
    "    - SVD is undefined when the matrix has missing entries.      \n",
    "    \n",
    "**Possible solutions**\n",
    "- How about applying some imputation of the missing values? \n",
    "    - Inaccurate imputation might distort the data\n",
    "    - The loss function will be dominated by large number of entries which are not part of the real data\n",
    "- How about **summing over only the available ratings in $R$**?\n",
    "    - Prone to overfitting    \n",
    "    $$f(Z, W) = \\sum_{(i,j) \\in R} ((w_j^Tz_i) - y_{ij})^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A typical loss function for recommendation systems**\n",
    "\n",
    "- Consider only observed ratings and add regularization to avoid overfitting. \n",
    "- Here we are adding L2 regularization to penalize weights in $W$ and $Z$. \n",
    "\n",
    "$$f(Z, W) = \\sum_{(i,j) \\in R} ((w_j^Tz_i) - y_{ij})^2 + \\frac{\\lambda_1}{2}\\lVert Z \\lVert_2^2 + \\frac{\\lambda_2}{2}\\lVert W \\lVert_2^2$$\n",
    "\n",
    "- This regularized SVD gave 7% improvement on the Netflix problem! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**(Optional) Optimization**\n",
    "\n",
    "Two algorithms are commonly used to minimize this objective function:\n",
    "\n",
    "- Stochastic gradient descent (SGD) \n",
    "- Weighted Alternating Least Squares (WALS) is specialized to this particular loss function\n",
    "    - Allows for massive parallelization \n",
    "    - Preferred when the data is implicit data and not sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**(Optional) Adding Global/User/Item biases**\n",
    "\n",
    "- Our standard latent-factor model gives reconstructions for entries in matrix $Y$ as \n",
    "\n",
    "$$\\hat{y}_{ij} = w^T_jz_i$$\n",
    "\n",
    "- Sometimes we don't assume the $y_{ij}$ has a mean of zero. \n",
    "- We could add bias $\\beta$ reflecting average overall rating:\n",
    "\n",
    "$$\\hat{y}_{ij} = \\beta + w^T_jz_i$$\n",
    "\n",
    "- We could also add user-specific bias $\\beta_i$ and item-specific bias $\\beta_j$\n",
    "\n",
    "$$\\hat{y}_{ij} = \\beta + \\beta_i + \\beta_j + w^T_jz_i$$\n",
    "\n",
    "- Some users rate things higher on average and some movies are rated higher on average. \n",
    "- The bias terms can also be regularized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.5 `surprise` package for rating prediction \n",
    "\n",
    "- Since our loss function is slightly different, we cannot really use PCA or LSA implementations in `scikit-learn`. \n",
    "- We'll be using a package called [Surprise](https://surprise.readthedocs.io/en/stable/index.html). \n",
    "\n",
    "```\n",
    "pip install scikit-surprise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [This package](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#matrix-factorization-based-algorithms) implements the famous SVD algorithm popularized during Netflix Prize. \n",
    "- The loss function above is minimized using stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try it out on our toy utility matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's predict ratings with collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(toy_ratings, reader)  # Load the data\n",
    "\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.01, random_state=42\n",
    ")  # Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='Pat', iid='Lion King', r_ui=5.0, est=4.418103946765089, details={'was_impossible': False}),\n",
       " Prediction(uid='Pat', iid='The Little Mermaid', r_ui=4.0, est=4.3238904851989135, details={'was_impossible': False}),\n",
       " Prediction(uid='Pat', iid='Bambi', r_ui=5.0, est=4.429962029063298, details={'was_impossible': False}),\n",
       " Prediction(uid='Jim', iid='The Social Dilemma', r_ui=5.0, est=4.074699112946736, details={'was_impossible': False}),\n",
       " Prediction(uid='Jim', iid='Malcolm x', r_ui=4.0, est=4.2490893833663055, details={'was_impossible': False}),\n",
       " Prediction(uid='Jim', iid='Man on Wire', r_ui=5.0, est=4.435013885036921, details={'was_impossible': False}),\n",
       " Prediction(uid='Sam', iid='Lion King', r_ui=5.0, est=4.247622025394618, details={'was_impossible': False}),\n",
       " Prediction(uid='Sam', iid='The Little Mermaid', r_ui=5.0, est=4.157477218712453, details={'was_impossible': False}),\n",
       " Prediction(uid='Sam', iid='Toy Story', r_ui=4.0, est=3.81385601327263, details={'was_impossible': False}),\n",
       " Prediction(uid='Sam', iid='The Social Dilemma', r_ui=1.0, est=3.883247434553506, details={'was_impossible': False}),\n",
       " Prediction(uid='Sam', iid='Bambi', r_ui=5.0, est=4.245514990652595, details={'was_impossible': False}),\n",
       " Prediction(uid='Eva', iid='Toy Story', r_ui=1.0, est=3.6186861930694434, details={'was_impossible': False}),\n",
       " Prediction(uid='Eva', iid='Man on Wire', r_ui=5.0, est=4.094092586099001, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 2\n",
    "algo = SVD(n_factors=k, random_state=42)\n",
    "algo.fit(trainset)\n",
    "preds = algo.test(trainset.build_testset())\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rating_preds = defaultdict(list)\n",
    "for uid, iid, true_r, est, _ in preds:\n",
    "    rating_preds[uid].append((iid, est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Pat': [('Lion King', 4.418103946765089),\n",
       "              ('The Little Mermaid', 4.3238904851989135),\n",
       "              ('Bambi', 4.429962029063298)],\n",
       "             'Jim': [('The Social Dilemma', 4.074699112946736),\n",
       "              ('Malcolm x', 4.2490893833663055),\n",
       "              ('Man on Wire', 4.435013885036921)],\n",
       "             'Sam': [('Lion King', 4.247622025394618),\n",
       "              ('The Little Mermaid', 4.157477218712453),\n",
       "              ('Toy Story', 3.81385601327263),\n",
       "              ('The Social Dilemma', 3.883247434553506),\n",
       "              ('Bambi', 4.245514990652595)],\n",
       "             'Eva': [('Toy Story', 3.6186861930694434),\n",
       "              ('Man on Wire', 4.094092586099001)]})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the validation RMSE? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_preds = algo.test(validset)\n",
    "accuracy.rmse(svd_preds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Cross-validation for recommender systems**\n",
    "\n",
    "- We can also carry out cross-validation and grid search with this package. \n",
    "- Let's look at an example of cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "pd.DataFrame(cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=3, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ❓❓ Questions for you\n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/NGJD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 7.2 Select all of the following statements which are **True** (iClicker)\n",
    "\n",
    "- (A) Collaborative filtering is a technique used to make recommendations based on the preferences of similar users or items. \n",
    "- (B) The primary difference between PCA and collaborative filtering is that the loss function in the latter only includes the available ratings and regularization terms. \n",
    "- (C) When you apply collaborative filtering on movie ratings data with ratings in the range 0 to 5, it's possible to get a predicted rating outside that range. \n",
    "- (D) Collaborative filtering might have problems if a new item shows up. \n",
    "- (E) Collaborative filtering might have problems if a new user shows up.\n",
    "  \n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} V's Solutions!\n",
    ":class: tip, dropdown\n",
    "- A, B, C, D, E \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final comments and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Formulating the problem of recommender systems** \n",
    "\n",
    "- We are given ratings data. \n",
    "- We use this data to create **utility matrix** which encodes interactions between users and items. \n",
    "- The utility matrix has many missing entries. \n",
    "- We defined recommendation systems problem as **matrix completion problem**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Collaborative filtering**\n",
    "\n",
    "- Collaborative filtering is an unsupervised approach to recommendation systems.  \n",
    "- Surprisingly we use PCA-like approach.  \n",
    "- We factorize the utility matrix into $Z$ and $W$.\n",
    "- $Z$ has embeddings for users with latent features of items \n",
    "- $W^T$ has embeddings for items with latent features of users\n",
    "- The key idea is that the loss function only includes the available ratings and regularization terms for $W$ and $Z$ to avoid overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Be mindful of the consequences recommendation systems. \n",
    "- Companies such as Amazon,  Netflix, Facebook, Google (YouTube), which extensively use recommendation systems, are profit-driven and so they design these systems to maximize user attention; their focus is not necessarily human well-being. \n",
    "- There are tons of news and research articles on serious consequences of recommendation systems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Some weird stories which got media attention.   \n",
    "[How Target Figured Out A Teen Girl Was Pregnant Before Her Father Did](https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/?sh=3171af136668)\n",
    "- More serious consequences are in political contexts. \n",
    "    - [Facebook Admits It Was Used to Incite Violence in Myanmar](https://www.nytimes.com/2018/11/06/technology/myanmar-facebook.html)\n",
    "    - [YouTube Extremism and the Long Tail](https://www.theatlantic.com/politics/archive/2018/03/youtube-extremism-and-the-long-tail/555350/)        \n",
    "- Check out this recent article: [Users, advertisers – we are all trapped in the 'enshittification' of the internet](https://www.theguardian.com/commentisfree/2023/mar/11/users-advertisers-we-are-all-trapped-in-the-enshittification-of-the-internet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**My advice**\n",
    "\n",
    "- Ask hard and uncomfortable questions to yourself (and to your employer if possible) before implementing and deploying such systems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources \n",
    "\n",
    "- [MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS](https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf)\n",
    "- [Recommendation Systems chapter from Dive into Deep Learning](https://www.d2l.ai/chapter_recommender-systems/index.html)\n",
    "- [Google developer's advanced courses](https://developers.google.com/machine-learning/recommendation)\n",
    "- [Collaborative filtering for recommendation systems in Python, by N. Hug](https://www.youtube.com/watch?v=z0dx-YckFko)\n",
    "- [An interesting talk: The paradox of choice](https://www.ted.com/talks/barry_schwartz_the_paradox_of_choice)\n",
    "- [How Netflix’s Recommendations System Works](https://help.netflix.com/en/node/100639)\n",
    "- [Hands on Recommendation Systems with Python](https://learning.oreilly.com/library/view/hands-on-recommendation-systems/9781788993753/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:563]",
   "language": "python",
   "name": "conda-env-563-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
