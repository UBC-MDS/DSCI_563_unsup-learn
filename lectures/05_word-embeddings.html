

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lecture 5: Word Embeddings, word2vec &#8212; DSCI 563 Unsupervised Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/05_word-embeddings';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lecture 6: Using word embeddings, manifold learning" href="06_more-word2vec-tsne.html" />
    <link rel="prev" title="Lecture 4: More PCA, LSA, and NMF" href="04_More-PCA-LSA-NMF.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/mds-hex-sticker.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/mds-hex-sticker.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="00_course-information.html">Course Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="01_K-Means.html">Lecture 1: K-Means Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_DBSCAN-hierarchical.html">Lecture 2: DBSCAN and Hierarchical Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_PCA-intro.html">Lecture 3: Introduction to Principal Component Analysis (PCA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_More-PCA-LSA-NMF.html">Lecture 4: More PCA, LSA, and NMF</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lecture 5: Word Embeddings, word2vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_more-word2vec-tsne.html">Lecture 6: Using word embeddings, manifold learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_recommender-systems1.html">Lecture 7: Recommender Systems Part I</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_recommender-systems2.html">Lecture 8: Recommender Systems Part 2</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="AppendixA.html">Appendix A: K-Means customer segmentation case study</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Class demos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="class_demos/01_class-demo.html">Lecture 01: Clustering class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="class_demos/02_class-demo.html">Lecture 02: Clustering class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="class_demos/03_class-demo.html">Lecture 03: PCA applications class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="class_demos/07_class-demo.html">Lecture 07: Collaborative filtering class demo</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Attribution</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../attribution.html">Attributions</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.ubc.ca/MDS-2022-23/DSCI_563_unsup-learn" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lectures/05_word-embeddings.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 5: Word Embeddings, word2vec</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-plan-imports-los">Lecture plan, imports, LOs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-plan">Lecture plan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-outcomes">Learning outcomes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation-and-context">1. Motivation and context</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activity-context-and-word-meaning">1.1 Activity: Context and word meaning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word-representations-intro">Word representations: intro</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-representations">2. Word representations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activity-brainstorm-ways-to-represent-words-2-mins">Activity:  Brainstorm ways to represent words (~2 mins)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simplest-representation-one-hot-representation-of-words">2.1 Simplest representation: One-hot representation of words</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#term-term-co-occurrence-matrix">2.2 Term-term co-occurrence matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-word-vectors-and-similarity">Visualizing word vectors and similarity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Visualizing word vectors and similarity</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dense-representations">3. Dense representations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-can-we-do-with-these-word-representations">3.1 What can we do with these word representations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-dense-representations">3.2 Creating dense representations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-dense-embeddings-with-lsa">3.2.1 (Optional) Dense embeddings with LSA</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec">3.2.2 word2vec</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simple-neural-network-architecture-source">A simple neural network architecture (Source)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram-objective">Skip-gram objective</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#questions-for-you">❓❓ Questions for you</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-1-select-all-of-the-following-statements-which-are-true-iclicker">Exercise 5.1 Select all of the following statements which are <strong>True</strong> (iClicker)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-word2vec">4. More word2vec</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram-demo-with-toy-data">4.1 Skip-gram demo with toy data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-word2vec-embeddings">4.2 Training word2vec embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-trained-embeddings">4.3 Pre-trained embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#success-of-word2vec">4.4 Success of word2vec</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implicit-biases-and-stereotypes-in-word-embeddings">4.5 Implicit biases and stereotypes in word embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-popular-methods-to-get-embeddings">4.6 Other popular methods to get embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fasttext">fastText</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-glove-global-vectors-for-word-representation">(Optional) GloVe: Global Vectors for Word Representation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">❓❓ Questions for you</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-2-select-all-of-the-following-statements-which-are-true-iclicker">Exercise 5.2 Select all of the following statements which are <strong>True</strong> (iClicker)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-comments-summary-and-reflection">Final comments, summary, and reflection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word-embeddings">Word embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">word2vec</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Pre-trained embeddings</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resources">Resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fun-tools">Fun tools</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><img alt="" src="../_images/563_banner.png" /></p>
<section class="tex2jax_ignore mathjax_ignore" id="lecture-5-word-embeddings-word2vec">
<h1>Lecture 5: Word Embeddings, word2vec<a class="headerlink" href="#lecture-5-word-embeddings-word2vec" title="Permalink to this heading">#</a></h1>
<p>UBC Master of Data Science program, 2023-24</p>
<p>Instructor: Varada Kolhatkar</p>
<section id="lecture-plan-imports-los">
<h2>Lecture plan, imports, LOs<a class="headerlink" href="#lecture-plan-imports-los" title="Permalink to this heading">#</a></h2>
<section id="lecture-plan">
<h3>Lecture plan<a class="headerlink" href="#lecture-plan" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Introduction and motivation (~5 mins)</p></li>
<li><p>Summary of pre-watch videos (~20 mins)</p></li>
<li><p>Demo of word2vec skipgram (extremely inefficient version) on a toy corpus (~10 mins)</p></li>
<li><p>Q&amp;A and T/F questions (~5 mins )</p></li>
<li><p>Break (~5 mins)</p></li>
<li><p>Training word2vec (~10 mins)</p></li>
<li><p>Word analogies, biases and stereotypes in word embeddings (~10 mins)</p></li>
<li><p>Q&amp;A and T/F questions (~5 mins )</p></li>
<li><p>Final comments, summary, reflection (~5 mins)</p></li>
</ul>
<p><br><br><br><br></p>
</section>
<section id="imports">
<h3>Imports<a class="headerlink" href="#imports" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">),</span> <span class="s2">&quot;code&quot;</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">comat</span> <span class="kn">import</span> <span class="n">CooccurrenceMatrix</span>
<span class="kn">from</span> <span class="nn">preprocessing</span> <span class="kn">import</span> <span class="n">MyPreprocessor</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">TruncatedSVD</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="c1"># from support_functions import *</span>

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;font.size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">16</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_colwidth&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><br><br><br><br></p>
</section>
<section id="learning-outcomes">
<h3>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Permalink to this heading">#</a></h3>
<p>From this lecture, students are expected to be able to:</p>
<ul class="simple">
<li><p>Explain the general idea of a vector space model.</p></li>
<li><p>Explain the difference between different word representations: one-hot encoding, term-term co-occurrence matrix representation, and word2vec representation.</p></li>
<li><p>Explain the skip-gram model at a high level.</p></li>
<li><p>Load and use pre-trained word embeddings to find word similarities and analogies.</p></li>
<li><p>Train your own word vectors with <code class="docutils literal notranslate"><span class="pre">Gensim</span></code>.</p></li>
<li><p>Use word2vec models for word similarity and analogies.</p></li>
<li><p>Demonstrate biases in word2vec models and learn to watch out for such biases in pre-trained embeddings.</p></li>
</ul>
<p><br><br><br><br></p>
</section>
</section>
<section id="motivation-and-context">
<h2>1. Motivation and context<a class="headerlink" href="#motivation-and-context" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Do large language models, such as ChatGPT, “understand” your questions to some extent and provide useful responses?</p></li>
<li><p>What is required for a machine to “understand” language?</p></li>
<li><p>Last week, we discussed representing numeric data with PCA and text with LSA or TruncatedSVD.</p></li>
<li><p>So far we have been talking about sentence or document representations.</p></li>
<li><p>This week, we’ll go one step back and talk about word representations.</p></li>
<li><p>Why? Because word is a basic semantic unit of text and in order to capture meaning of text it is useful to capture word meaning (e.g., in terms of relationships between words).</p></li>
</ul>
<section id="activity-context-and-word-meaning">
<h3>1.1 Activity: Context and word meaning<a class="headerlink" href="#activity-context-and-word-meaning" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Pair up with the person next to you and try to guess the meanings of two made-up words: <strong>flibbertigibbet</strong> and <strong>groak</strong>.</p></li>
</ul>
<blockquote>
<div><ol class="arabic simple">
<li><p>The plot twist was totally unexpected, making it a <strong>flibbertigibbet</strong> experience.</p></li>
<li><p>Despite its <strong>groak</strong> special effects, the storyline captivated my attention till the end.</p></li>
<li><p>I found the character development rather <strong>groak</strong>, failing to evoke empathy.</p></li>
<li><p>The cinematography is <strong>flibbertigibbet</strong>, showcasing breathtaking landscapes.</p></li>
<li><p>A <strong>groak</strong> narrative that could have been saved with better direction.</p></li>
<li><p>This movie offers a <strong>flibbertigibbet</strong> blend of humour and action, a must-watch.</p></li>
<li><p>Sadly, the movie’s potential was overshadowed by its <strong>groak</strong> pacing.</p></li>
<li><p>The soundtrack complemented the film’s theme perfectly, adding to its <strong>flibbertigibbet</strong> charm.</p></li>
<li><p>It’s rare to see such a <strong>flibbertigibbet</strong> performance by the lead actor.</p></li>
<li><p>Despite high expectations, the film turned out to be quite <strong>groak</strong>.</p></li>
<li><p><strong>Flibbertigibbet</strong> dialogues and a gripping plot make this movie stand out.</p></li>
<li><p>The film’s <strong>groak</strong> screenplay left much to be desired.</p></li>
</ol>
</div></blockquote>
<p>Attributions: Thanks to ChatGPT!</p>
<ul class="simple">
<li><p>How did you infer the meaning of the words <strong>flibbertigibbet</strong> and <strong>groak</strong>?</p></li>
<li><p>Which specific words or phrases in the context helped you infer the meaning of these imaginary words?</p></li>
</ul>
<p><br><br><br><br></p>
<p>What you did in the above activity is referred to as <strong>distributional hypothesis</strong>.</p>
<blockquote> 
    <p>You shall know a word by the company it keeps.</p>
    <footer>Firth, 1957</footer>        
</blockquote>
<blockquote> 
If A and B have almost identical environments we say that they are synonyms.
<footer>Harris, 1954</footer>    
</blockquote>    
<p>Example:</p>
<ul class="simple">
<li><p>The plot twist was totally unexpected, making it a <strong>flibbertigibbet</strong> experience.</p></li>
<li><p>The plot twist was totally unexpected, making it a <strong>delightful</strong> experience.</p></li>
</ul>
</section>
<section id="word-representations-intro">
<h3>Word representations: intro<a class="headerlink" href="#word-representations-intro" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>A standard way to represent meanings of words is by placing them into a vector space.</p></li>
<li><p>Distances between words in the vector space indicate relationships between them.</p></li>
<li></li>
</ul>
<a class="reference internal image-reference" href="../_images/t-SNE_word_embeddings.png"><img alt="../_images/t-SNE_word_embeddings.png" src="../_images/t-SNE_word_embeddings.png" style="width: 600px; height: 600px;" /></a>
<!-- ![](img/t-SNE_word_embeddings.png) -->
<p>(Attribution: <a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/">Jurafsky and Martin 3rd edition</a>)</p>
<ul class="simple">
<li><p>Word meaning has been a favourite topic of philosophers for centuries.</p></li>
<li><p>An example from legal domain: <a class="reference external" href="https://www.scc-csc.ca/case-dossier/info/sum-som-eng.aspx?cas=36258">Are hockey gloves “gloves, mittens, mitts” or “articles of plastics”?</a></p></li>
</ul>
<blockquote>
Canada (A.G.) v. Igloo Vikski Inc. was a tariff code case that made its way to the SCC (Supreme Court of Canada). The case disputed the definition of hockey gloves as either "gloves, mittens, or mitts" or as "other articles of plastic."
</blockquote>
<p><img alt="" src="../_images/hockey_gloves_case.png" /></p>
<!-- <center>
<img src="img/hockey_gloves_case.png" width="500" height="500">
</center>
 --><p>In ML and Natural Language Processing (NLP) we are interested in</p>
<ul class="simple">
<li><p>Modeling word meaning that allows us to</p>
<ul>
<li><p>draw useful inferences to solve meaning-related problems</p></li>
<li><p>find relationship between words, e.g., which words are similar, which ones have positive or negative connotations</p></li>
</ul>
</li>
</ul>
<p><strong>Example: Word similarity</strong></p>
<ul class="simple">
<li><p>Suppose you are carrying out sentiment analysis.</p></li>
<li><p>Consider the sentences below.</p></li>
</ul>
<blockquote>
<div><p>S1: This movie offers a <strong>flibbertigibbet</strong> blend of humour and action, a must-watch.</p>
</div></blockquote>
<blockquote>
<div><p>S2: This movie offers a <strong>delightful</strong> blend of humour and action, a must-watch.</p>
</div></blockquote>
<ul class="simple">
<li><p>Here we would like to capture similarity between <strong>flibbertigibbet</strong> and <strong>delightful</strong> in reference to sentiment analysis task.</p></li>
</ul>
<p><strong>How are word embeddings related to unsupervised learning?</strong></p>
<ul class="simple">
<li><p>They are closely related to dimensionality reduction and extracting meaningful representations from raw data.</p></li>
<li><p>The word2vec algorithm is an unsupervised (or semi-supervised) method; we do not need any labeled data but we use running text as supervision signal.</p></li>
<li><p>We can build recommendation systems using word2vec algorithm (you’ll explore this in the lab) which is the topic of next week.</p></li>
</ul>
<p><br><br><br><br></p>
</section>
</section>
<section id="word-representations">
<h2>2. Word representations<a class="headerlink" href="#word-representations" title="Permalink to this heading">#</a></h2>
<section id="activity-brainstorm-ways-to-represent-words-2-mins">
<h3>Activity:  Brainstorm ways to represent words (~2 mins)<a class="headerlink" href="#activity-brainstorm-ways-to-represent-words-2-mins" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Suppose you are building a question answering system and you are given the following question and three candidate answers.</p></li>
<li><p>What kind of relationship between words would we like our representation to capture in order to arrive at the correct answer?</p></li>
</ul>
<blockquote>       
<p style="font-size:20px"><b>Question:</b> How <b>tall</b> is Machu Picchu?</p>
    <p style="font-size:20px"><b>Candidate 1:</b> Machu Picchu is 13.164 degrees south of the equator.</p>    
<p style="font-size:20px"><b>Candidate 2:</b> The official height of Machu Picchu is 2,430 m.</p>
<p style="font-size:20px"><b>Candidate 3:</b> Machu Picchu is 80 kilometres (50 miles) northwest of Cusco.</p>    
</blockquote> 
<ul class="simple">
<li><p>Let’s explore different ways to represent words.</p></li>
<li><p>First, let’s look at two simplistic word representations</p>
<ul>
<li><p>One-hot representation</p></li>
<li><p>Term-term co-occurrence matrix</p></li>
</ul>
</li>
</ul>
</section>
<section id="simplest-representation-one-hot-representation-of-words">
<h3>2.1 Simplest representation: One-hot representation of words<a class="headerlink" href="#simplest-representation-one-hot-representation-of-words" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Example: Consider the sentence</p></li>
</ul>
<blockquote>
<div><p>How tall is Machu_Picchu ?</p>
</div></blockquote>
<ul class="simple">
<li><p>What is the one-hot representation for the word <em>tall</em>?</p>
<ul>
<li><p>Vocabulary size = 5 and index of the word <em>tall</em> = 1</p></li>
<li><p>One-hot vector for <em>tall</em>: <span class="math notranslate nohighlight">\(\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\)</span></p></li>
</ul>
</li>
<li><p>Build <strong>vocabulary</strong> containing all unique words in the corpus.</p></li>
<li><p>One-hot representation of a word is a vector of length <span class="math notranslate nohighlight">\(V\)</span> such that the value at word index is 1 and all other indices is 0.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_onehot_encoding</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
    <span class="n">onehot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>
    <span class="n">onehot</span><span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">onehot</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>


<span class="k">def</span> <span class="nf">print_cosine_similarity</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns similarity score between word1 and word2</span>
<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    df    -- (pandas.DataFrame)</span>
<span class="sd">        Dataframe containing word representations</span>
<span class="sd">    word1 -- (array)</span>
<span class="sd">        Representation of word1</span>
<span class="sd">    word2 -- (array)</span>
<span class="sd">        Representation of word2</span>

<span class="sd">    Returns</span>
<span class="sd">    --------</span>
<span class="sd">    None. Returns similarity score between word1 and word2 with the given representation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vec1</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">word1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">vec2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">word2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sim</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;The dot product between </span><span class="si">%s</span><span class="s2"> and </span><span class="si">%s</span><span class="s2">: </span><span class="si">%0.2f</span><span class="s2"> and cosine similarity is: </span><span class="si">%0.2f</span><span class="s2">&quot;</span>
        <span class="o">%</span> <span class="p">(</span><span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vec1</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">vec2</span><span class="o">.</span><span class="n">flatten</span><span class="p">()),</span> <span class="n">sim</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Vocabulary and one-hot encoding</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">(</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;how tall is machu_picchu ? the official height of machu_picchu is 2,430 m .&quot;&quot;&quot;</span>
<span class="p">)</span>
<span class="n">unique_words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">corpus</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
<span class="n">unique_words</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">index</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_words</span><span class="p">)}</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of the vocabulary: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Size of the vocabulary: 12
{&#39;.&#39;: 0, &#39;2,430&#39;: 1, &#39;?&#39;: 2, &#39;height&#39;: 3, &#39;how&#39;: 4, &#39;is&#39;: 5, &#39;m&#39;: 6, &#39;machu_picchu&#39;: 7, &#39;of&#39;: 8, &#39;official&#39;: 9, &#39;tall&#39;: 10, &#39;the&#39;: 11}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_onehot_encoding</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
<span class="n">ohe_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">ohe_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>.</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2,430</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>?</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>height</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>how</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>is</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>m</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>machu_picchu</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>of</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>official</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>tall</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>the</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_cosine_similarity</span><span class="p">(</span><span class="n">ohe_df</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">,</span> <span class="s2">&quot;height&quot;</span><span class="p">)</span>
<span class="n">print_cosine_similarity</span><span class="p">(</span><span class="n">ohe_df</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">,</span> <span class="s2">&quot;official&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The dot product between tall and height: 0.00 and cosine similarity is: 0.00
The dot product between tall and official: 0.00 and cosine similarity is: 0.00
</pre></div>
</div>
</div>
</div>
<p><strong>Problem with one-hot encoding</strong></p>
<ul class="simple">
<li><p>We would like the word representation to capture the similarity between <em>tall</em> and <em>height</em> and so we would like them to have bigger dot product or bigger cosine similarity (normalized dot product).</p></li>
<li><p>The problem with one-hot representation of words is that there is no inherent notion of relationship between words and the dot product between similar and non-similar words is zero.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split} 
\vec{tall}\cdot\vec{height} = 0\\ 
\end{split}\]</div>
<p><strong>Need a representation that captures relationships between words.</strong></p>
<ul class="simple">
<li><p>We will be looking at two such representations.</p>
<ol class="arabic simple">
<li><p>Sparse representation with <strong>term-term co-occurrence matrix</strong></p></li>
<li><p>Dense representation with <strong>word2vec skip-gram model</strong></p></li>
</ol>
</li>
</ul>
</section>
<section id="term-term-co-occurrence-matrix">
<h3>2.2 Term-term co-occurrence matrix<a class="headerlink" href="#term-term-co-occurrence-matrix" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>So far we have been talking about documents and we created document-term co-occurrence matrix (e.g., bag-of-words representation of text).</p></li>
<li><p>We can also do this with words. The idea is to go through a corpus of text, keeping a count of all of the words that appear in context of each word (within a window).</p></li>
<li><p>An example:</p></li>
</ul>
<!-- <center>
<img src="img/term-term_comat.png" width="600" height="600">
</center>
     -->
<p>(Credit: Jurafsky and Martin 3rd edition)</p>
</section>
<section id="visualizing-word-vectors-and-similarity">
<h3>Visualizing word vectors and similarity<a class="headerlink" href="#visualizing-word-vectors-and-similarity" title="Permalink to this heading">#</a></h3>
<!-- ![](img/word_vectors_and_angles.png) -->
<center>
<img src="img/word_vectors_and_angles.png" width="800" height="800">
</center>
<p>(Credit: Jurafsky and Martin 3rd edition)</p>
<ul class="simple">
<li><p>The similarity is calculated using dot products between word vectors.</p>
<ul>
<li><p>Example: <span class="math notranslate nohighlight">\(\vec{\text{digital}}.\vec{\text{information}} = 0 \times 1 + 1\times 6 = 6\)</span></p></li>
<li><p>Higher the dot product more similar the words.</p></li>
</ul>
</li>
</ul>
</section>
<section id="id1">
<h3>Visualizing word vectors and similarity<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<!-- ![](img/word_vectors_and_angles.png) -->
<a class="reference internal image-reference" href="../_images/word_vectors_and_angles.png"><img alt="../_images/word_vectors_and_angles.png" src="../_images/word_vectors_and_angles.png" style="width: 600px; height: 600px;" /></a>
<p>(Credit: Jurafsky and Martin 3rd edition)</p>
<ul class="simple">
<li><p>The similarity is calculated using dot products between word vectors.</p>
<ul>
<li><p>Example: <span class="math notranslate nohighlight">\(\vec{\text{digital}}.\vec{\text{information}} = 0 \times 1 + 1\times 6 = 6\)</span></p></li>
<li><p>Higher the dot product more similar the words.</p></li>
</ul>
</li>
<li><p>We can also calculate a normalized version of dot products.
$<span class="math notranslate nohighlight">\(similarity_{cosine}(w_1,w_2) = \frac{w_1.w_2}{\left\lVert w_1\right\rVert_2 \left\lVert w_2\right\rVert_2}\)</span>$</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;How tall is Machu Picchu?&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Machu Picchu is 13.164 degrees south of the equator.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The official height of Machu Picchu is 2,430 m.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Machu Picchu is 80 kilometres (50 miles) northwest of Cusco.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;It is 80 kilometres (50 miles) northwest of Cusco, on the crest of the mountain Machu Picchu, located about 2,430 metres (7,970 feet) above mean sea level, over 1,000 metres (3,300 ft) lower than Cusco, which has an elevation of 3,400 metres (11,200 ft).&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">sents</span> <span class="o">=</span> <span class="n">MyPreprocessor</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">CooccurrenceMatrix</span><span class="p">(</span>
    <span class="n">sents</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>  <span class="c1"># Let&#39;s build term-term co-occurrence matrix for our text.</span>
<span class="n">comat</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">comat</span><span class="o">.</span><span class="n">todense</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tall</th>
      <th>machu</th>
      <th>picchu</th>
      <th>13.164</th>
      <th>degrees</th>
      <th>south</th>
      <th>equator</th>
      <th>official</th>
      <th>height</th>
      <th>2,430</th>
      <th>...</th>
      <th>mean</th>
      <th>sea</th>
      <th>level</th>
      <th>1,000</th>
      <th>3,300</th>
      <th>ft</th>
      <th>lower</th>
      <th>elevation</th>
      <th>3,400</th>
      <th>11,200</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>tall</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>machu</th>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>picchu</th>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13.164</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>degrees</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 32 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_cosine_similarity</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">,</span> <span class="s2">&quot;height&quot;</span><span class="p">)</span>
<span class="n">print_cosine_similarity</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">,</span> <span class="s2">&quot;official&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The dot product between tall and height: 2.00 and cosine similarity is: 0.82
The dot product between tall and official: 1.00 and cosine similarity is: 0.50
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We are getting non-zero cosine similarity now and we are able to capture some similarities between words now.</p></li>
<li><p>That said similarities do not make much sense in the toy example above because we’re using a tiny corpus.</p></li>
<li><p>To find meaningful patterns of similarities between words, we need a large corpus.</p></li>
<li><p>Let’s try a bit larger corpus and check whether the similarities make sense.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">wikipedia</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">sent_tokenize</span><span class="p">,</span> <span class="n">word_tokenize</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">queries</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Machu Picchu&quot;</span><span class="p">,</span>
  <span class="c1"># &quot;Everest&quot;,</span>
    <span class="s2">&quot;Sequoia sempervirens&quot;</span><span class="p">,</span>
    <span class="s2">&quot;President (country)&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Politics Canada&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">queries</span><span class="p">)):</span>
    <span class="n">sents</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">wikipedia</span><span class="o">.</span><span class="n">page</span><span class="p">(</span><span class="n">queries</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="n">corpus</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">sents</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of sentences in the corpus: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of sentences in the corpus:  709
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sents</span> <span class="o">=</span> <span class="n">MyPreprocessor</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">CooccurrenceMatrix</span><span class="p">(</span><span class="n">sents</span><span class="p">)</span>
<span class="n">comat</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">comat</span><span class="o">.</span><span class="n">todense</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>machu</th>
      <th>picchu</th>
      <th>15th-century</th>
      <th>inca</th>
      <th>citadel</th>
      <th>located</th>
      <th>eastern</th>
      <th>cordillera</th>
      <th>southern</th>
      <th>peru</th>
      <th>...</th>
      <th>comprehensive</th>
      <th>overview</th>
      <th>cbc</th>
      <th>digital</th>
      <th>archives</th>
      <th>boondoggles</th>
      <th>elephants</th>
      <th>campaigning</th>
      <th>compared</th>
      <th>textbook</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>machu</th>
      <td>0</td>
      <td>79</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>picchu</th>
      <td>79</td>
      <td>0</td>
      <td>1</td>
      <td>6</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15th-century</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>inca</th>
      <td>5</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>citadel</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>boondoggles</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>elephants</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>campaigning</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>compared</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>textbook</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>4190 rows × 4190 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_cosine_similarity</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">,</span> <span class="s2">&quot;height&quot;</span><span class="p">)</span>
<span class="n">print_cosine_similarity</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">,</span> <span class="s2">&quot;official&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The dot product between tall and height: 18.00 and cosine similarity is: 0.33
The dot product between tall and official: 0.00 and cosine similarity is: 0.00
</pre></div>
</div>
</div>
</div>
<p><br><br><br><br></p>
</section>
</section>
<section id="dense-representations">
<h2>3. Dense representations<a class="headerlink" href="#dense-representations" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>The goal is to learn general purpose embeddings that are useful for common tasks involving text data.</p></li>
</ul>
<p><strong>Sparse vs. dense word vectors</strong></p>
<ul class="simple">
<li><p>Term-term co-occurrence matrix representation is long and sparse.</p>
<ul>
<li><p>length |V| is usually large (e.g., &gt; 50,000)</p></li>
<li><p>most elements are zero</p></li>
</ul>
</li>
<li><p>OK because there are efficient ways to deal with sparse matrices.</p></li>
</ul>
<ul class="simple">
<li><p>Learn short (~100 to 1000 dimensions) and dense vectors.</p></li>
<li><p>Short vectors are usually easier to train with ML models (less weights to train).</p></li>
<li><p>They may generalize better.</p></li>
<li><p>In practice they work much better!</p></li>
</ul>
<section id="what-can-we-do-with-these-word-representations">
<h3>3.1 What can we do with these word representations<a class="headerlink" href="#what-can-we-do-with-these-word-representations" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Before looking at how to create dense word representations let’s see how they look like and
what can we do with them.</p></li>
<li><p>Below I am loading word vectors trained on Google News corpus.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># It&#39;ll take a while to run this when you try it out for the first time.</span>
<span class="kn">import</span> <span class="nn">gensim.downloader</span> <span class="k">as</span> <span class="nn">api</span>

<span class="n">google_news_vectors</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;word2vec-google-news-300&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of vocabulary: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">google_news_vectors</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Size of vocabulary:  3000000
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">google_news_vectors</span></code> above has 300 dimensional word vectors for 3,000,000 unique words from Google news.</p></li>
</ul>
<ul class="simple">
<li><p>Let’s examine word vector for the word UBC.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">google_news_vectors</span><span class="p">[</span><span class="s2">&quot;UBC&quot;</span><span class="p">][:</span><span class="mi">20</span><span class="p">]</span>  <span class="c1"># Representation of the word UBC</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.3828125 , -0.18066406,  0.10644531,  0.4296875 ,  0.21582031,
       -0.10693359,  0.13476562, -0.08740234, -0.14648438, -0.09619141,
        0.02807617,  0.01409912, -0.12890625, -0.21972656, -0.41210938,
       -0.1875    , -0.11914062, -0.22851562,  0.19433594, -0.08642578],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">google_news_vectors</span><span class="p">[</span><span class="s2">&quot;UBC&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(300,)
</pre></div>
</div>
</div>
</div>
<p>Indeed it is a short and a dense vector!</p>
<p><strong>Finding similar words</strong></p>
<ul class="simple">
<li><p>Given word <span class="math notranslate nohighlight">\(w\)</span>, search in the vector space for the word closest to <span class="math notranslate nohighlight">\(w\)</span> as measured by cosine distance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">google_news_vectors</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s2">&quot;UBC&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;UVic&#39;, 0.788647472858429),
 (&#39;SFU&#39;, 0.7588527202606201),
 (&#39;Simon_Fraser&#39;, 0.7356573939323425),
 (&#39;UFV&#39;, 0.6880434155464172),
 (&#39;VIU&#39;, 0.6778583526611328),
 (&#39;Kwantlen&#39;, 0.6771427989006042),
 (&#39;UBCO&#39;, 0.6734487414360046),
 (&#39;UPEI&#39;, 0.6731125116348267),
 (&#39;UBC_Okanagan&#39;, 0.6709135174751282),
 (&#39;Lakehead_University&#39;, 0.662250816822052)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">google_news_vectors</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s2">&quot;information&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;info&#39;, 0.7363681793212891),
 (&#39;infomation&#39;, 0.680029571056366),
 (&#39;infor_mation&#39;, 0.6733849048614502),
 (&#39;informaiton&#39;, 0.6639008522033691),
 (&#39;informa_tion&#39;, 0.6601257920265198),
 (&#39;informationon&#39;, 0.633933424949646),
 (&#39;informationabout&#39;, 0.6320980787277222),
 (&#39;Information&#39;, 0.6186580657958984),
 (&#39;informaion&#39;, 0.6093292236328125),
 (&#39;details&#39;, 0.6063088178634644)]
</pre></div>
</div>
</div>
</div>
<p>If you want to extract all documents containing words similar to <strong>information</strong>, you could use this information.</p>
<p>Google News embeddings also support multi-word phrases.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">google_news_vectors</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s2">&quot;British_Columbia&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;BC&#39;, 0.7640387415885925),
 (&#39;Alberta&#39;, 0.7285022735595703),
 (&#39;Ontario&#39;, 0.7031311392784119),
 (&#39;Vancouver&#39;, 0.6976040005683899),
 (&#39;Lower_Mainland&#39;, 0.6730169057846069),
 (&#39;Saskatchewan&#39;, 0.6690970063209534),
 (&#39;Manitoba&#39;, 0.6569437980651855),
 (&#39;Canada&#39;, 0.6478375792503357),
 (&#39;Kamloops&#39;, 0.6449971795082092),
 (&#39;Nanaimo_BC&#39;, 0.6426822543144226)]
</pre></div>
</div>
</div>
</div>
<p><strong>Finding similarity scores between words</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">google_news_vectors</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s2">&quot;Canada&quot;</span><span class="p">,</span> <span class="s2">&quot;hockey&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.27610135
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">google_news_vectors</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s2">&quot;Japan&quot;</span><span class="p">,</span> <span class="s2">&quot;hockey&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0019627833
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word_pairs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;height&quot;</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;height&quot;</span><span class="p">,</span> <span class="s2">&quot;official&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;pineapple&quot;</span><span class="p">,</span> <span class="s2">&quot;mango&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;pineapple&quot;</span><span class="p">,</span> <span class="s2">&quot;juice&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;sun&quot;</span><span class="p">,</span> <span class="s2">&quot;robot&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;GPU&quot;</span><span class="p">,</span> <span class="s2">&quot;hummus&quot;</span><span class="p">),</span>
<span class="p">]</span>
<span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">word_pairs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;The similarity between </span><span class="si">%s</span><span class="s2"> and </span><span class="si">%s</span><span class="s2"> is </span><span class="si">%0.3f</span><span class="s2">&quot;</span>
        <span class="o">%</span> <span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">google_news_vectors</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The similarity between height and tall is 0.473
The similarity between height and official is 0.002
The similarity between pineapple and mango is 0.668
The similarity between pineapple and juice is 0.418
The similarity between sun and robot is 0.029
The similarity between GPU and hummus is 0.094
</pre></div>
</div>
</div>
</div>
<p>We are getting reasonable word similarity scores!!</p>
<p><br><br></p>
</section>
<section id="creating-dense-representations">
<h3>3.2 Creating dense representations<a class="headerlink" href="#creating-dense-representations" title="Permalink to this heading">#</a></h3>
<!-- ![](img/word2vec.png) -->
<center>
<img src="img/word2vec.png" width="600" height="600">
</center>    
<p>There are two classes of approaches.</p>
<ul class="simple">
<li><p>LSA (also referred to as count-based approaches)</p></li>
<li><p>word2vec (prediction-based approaches)</p></li>
</ul>
<section id="optional-dense-embeddings-with-lsa">
<h4>3.2.1 (Optional) Dense embeddings with LSA<a class="headerlink" href="#optional-dense-embeddings-with-lsa" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>How can we get such dense word embeddings?</p></li>
<li><p>Can we use LSA to get such short and dense representations?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">CooccurrenceMatrix</span><span class="p">(</span><span class="n">sents</span><span class="p">)</span>
<span class="n">comat</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lsa</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lsa</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">comat</span><span class="p">)</span>
<span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">lsa</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">comat</span><span class="p">)</span>
<span class="n">lsa_rep_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lsa_rep_df</span>  <span class="c1"># word representations learned with LSA</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>machu</th>
      <td>59.744787</td>
      <td>-56.048148</td>
      <td>-9.476625</td>
      <td>-2.125471</td>
      <td>-0.931832</td>
      <td>0.091583</td>
      <td>0.016552</td>
      <td>0.123792</td>
      <td>-0.092774</td>
      <td>0.092224</td>
    </tr>
    <tr>
      <th>picchu</th>
      <td>61.156957</td>
      <td>57.356851</td>
      <td>-10.068306</td>
      <td>-2.102533</td>
      <td>-1.328928</td>
      <td>-1.133096</td>
      <td>1.270330</td>
      <td>-0.369837</td>
      <td>0.059576</td>
      <td>0.420707</td>
    </tr>
    <tr>
      <th>15th-century</th>
      <td>1.425137</td>
      <td>-0.004821</td>
      <td>-0.271348</td>
      <td>-0.060159</td>
      <td>-0.064429</td>
      <td>0.009745</td>
      <td>-0.011915</td>
      <td>-0.053462</td>
      <td>0.043515</td>
      <td>-0.009831</td>
    </tr>
    <tr>
      <th>inca</th>
      <td>9.689077</td>
      <td>-0.487520</td>
      <td>-0.900727</td>
      <td>-0.141428</td>
      <td>-0.458294</td>
      <td>0.374853</td>
      <td>-0.345878</td>
      <td>-0.262844</td>
      <td>0.506327</td>
      <td>-0.231733</td>
    </tr>
    <tr>
      <th>citadel</th>
      <td>2.995572</td>
      <td>-1.302157</td>
      <td>-0.468748</td>
      <td>-0.161603</td>
      <td>-0.264666</td>
      <td>0.101359</td>
      <td>-0.069382</td>
      <td>-0.273455</td>
      <td>-0.001200</td>
      <td>0.171081</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>boondoggles</th>
      <td>0.023089</td>
      <td>-0.000278</td>
      <td>0.045347</td>
      <td>0.017567</td>
      <td>-0.036114</td>
      <td>-0.016962</td>
      <td>0.023338</td>
      <td>0.042295</td>
      <td>0.014989</td>
      <td>-0.018444</td>
    </tr>
    <tr>
      <th>elephants</th>
      <td>0.006440</td>
      <td>-0.000364</td>
      <td>0.037552</td>
      <td>-0.015651</td>
      <td>-0.026522</td>
      <td>-0.020554</td>
      <td>0.013983</td>
      <td>0.052387</td>
      <td>0.015443</td>
      <td>-0.012910</td>
    </tr>
    <tr>
      <th>campaigning</th>
      <td>0.080149</td>
      <td>0.005431</td>
      <td>0.468662</td>
      <td>-0.241442</td>
      <td>-0.180483</td>
      <td>0.207737</td>
      <td>-0.182761</td>
      <td>0.357888</td>
      <td>0.178600</td>
      <td>0.101775</td>
    </tr>
    <tr>
      <th>compared</th>
      <td>0.078030</td>
      <td>0.005072</td>
      <td>0.567311</td>
      <td>-0.333567</td>
      <td>-0.222730</td>
      <td>0.195864</td>
      <td>-0.187922</td>
      <td>0.471011</td>
      <td>0.309136</td>
      <td>0.103632</td>
    </tr>
    <tr>
      <th>textbook</th>
      <td>0.006850</td>
      <td>-0.000662</td>
      <td>0.051795</td>
      <td>-0.027355</td>
      <td>-0.036391</td>
      <td>-0.021673</td>
      <td>0.017683</td>
      <td>0.069401</td>
      <td>0.045774</td>
      <td>-0.022885</td>
    </tr>
  </tbody>
</table>
<p>4190 rows × 10 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_cosine_similarity</span><span class="p">(</span><span class="n">lsa_rep_df</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">,</span> <span class="s2">&quot;height&quot;</span><span class="p">)</span>
<span class="n">print_cosine_similarity</span><span class="p">(</span><span class="n">lsa_rep_df</span><span class="p">,</span> <span class="s2">&quot;tall&quot;</span><span class="p">,</span> <span class="s2">&quot;official&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The dot product between tall and height: 6.53 and cosine similarity is: 1.00
The dot product between tall and official: 0.02 and cosine similarity is: 0.00
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="word2vec">
<h3>3.2.2 word2vec<a class="headerlink" href="#word2vec" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>We can use LSA to get dense word embeddings.</p></li>
<li><p>In general, if we have a small dataset, embeddings extracted using LSA work better.</p></li>
<li><p>But an alternative and a more popular way to extract dense and short embeddings is using word2vec.</p></li>
<li><p>word2vec is a family of algorithms to create dense word embeddings using neural networks.</p></li>
</ul>
<p><strong>word2vec task</strong></p>
<p>Remember fill in the blank puzzles in your highschool tests?</p>
<blockquote>
<div><p>Add freshly squeezed ___ juice to your smoothie.</p>
</div></blockquote>
<ol class="arabic simple">
<li><p>pineapple</p></li>
<li><p>scarf</p></li>
<li><p>PCA</p></li>
<li><p>earthquake</p></li>
</ol>
<p>Another slightly non-intuitive way to think about this is what would be the context words given the target word <strong>pineapple</strong>?</p>
<blockquote>
<div><p>Add freshly ___ <strong>pineapple</strong> ___ to your smoothie.</p>
</div></blockquote>
<p>word2vec learns meaningful word representations by learning to solve large number of such fill in the blank puzzles.</p>
<ul class="simple">
<li><p>Based on this intuition, there are two primary algorithms</p>
<ul>
<li><p>Continuous bag of words (CBOW)</p></li>
<li><p><strong>Skip-gram</strong></p></li>
</ul>
</li>
<li><p>Two moderately efficient training methods</p>
<ul>
<li><p>Hierarchical softmax</p></li>
<li><p>Negative sampling</p></li>
</ul>
</li>
</ul>
<p><strong>word2vec: Skip-gram model</strong></p>
<ul class="simple">
<li><p>We are going to talk about the inefficient Skip-gram model, as it’s enough to get an intuition.</p></li>
<li><p>A neural network model to obtain short and dense representations of words.</p></li>
<li><p>A simple architecture with</p>
<ul>
<li><p>an input layer</p></li>
<li><p>a linear hidden layer (without any activation function)</p></li>
<li><p>an output layer with softmax</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>In skip-gram we work on an “auxiliary” supervised machine learning word prediction task of prediction context words given the target word.</p></li>
<li><p>We train a neural network for this task and the learned weights are our word vectors.</p></li>
<li><p>So we are not actually interested in making prediction about the context words.</p></li>
<li><p>Our goal is to learn meaningful weights (meaningful representation of the input) in the process.</p></li>
</ul>
<blockquote>
    Add freshly squeezed$_{context}$ pineapple$_{target}$ juice$_{context}$ to your smoothie. 
</blockquote> 
<!-- ![](img/target-context.png) -->
<center>
<img src="img/target-context.png" width="300" height="300">
</center>
<ul class="simple">
<li><p>So in the example above given the target word <strong>pineapple</strong></p>
<ul>
<li><p>what’s the probability that a randomly picked context word is <strong>juice</strong>.</p></li>
<li><p>what’s the probability that a randomly picked context word is <strong>squeezed</strong>.</p></li>
</ul>
</li>
<li><p>Given a <strong>target word</strong> (i.e., center word) word, predict <strong>context words</strong> (i.e., surrounding words).</p></li>
<li><p>Note that we are using “target” in a different sense here compared to how we use it in supervised machine learning.</p></li>
</ul>
</section>
<section id="a-simple-neural-network-architecture-source">
<h3>A simple neural network architecture (<a class="reference external" href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/">Source</a>)<a class="headerlink" href="#a-simple-neural-network-architecture-source" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>an input layer</p></li>
<li><p>a linear hidden layer (without any activation function)</p></li>
<li><p>an output layer with softmax</p></li>
</ul>
<!-- ![](img/word2vec_skipgram.png) -->
<a class="reference internal image-reference" href="../_images/word2vec_skipgram.png"><img alt="../_images/word2vec_skipgram.png" src="../_images/word2vec_skipgram.png" style="width: 600px; height: 800px;" /></a>
<!-- <center>
<img src="img/word2vec_skipgram.png" width="500" height="500">
</center>    
 -->
<!-- <img src="img/skipgram-juice.png" width="1000" height="1000"> -->
<p><img alt="" src="../_images/skipgram-juice.png" /></p>
<p><br><br></p>
<p><img alt="" src="../_images/skipgram-squeezed.png" /></p>
</section>
<section id="skip-gram-objective">
<h3>Skip-gram objective<a class="headerlink" href="#skip-gram-objective" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Consider the conditional probabilities <span class="math notranslate nohighlight">\(p(w_c|w_t)\)</span> and set the parameters <span class="math notranslate nohighlight">\(\theta\)</span> of <span class="math notranslate nohighlight">\(p(w_c|w_t; \theta)\)</span> so as to maximize the corpus probability.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\arg \max\limits_\theta \prod\limits_{(w_c,w_t) \in D} p(w_c|w_t;\theta)\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(w_t\)</span> → target word</p></li>
<li><p><span class="math notranslate nohighlight">\(w_c\)</span> → context word</p></li>
<li><p><span class="math notranslate nohighlight">\(D\)</span> → the set of all target and context pairs from the text</p></li>
<li><p><span class="math notranslate nohighlight">\(V\)</span> → vocabulary</p></li>
</ul>
<ul class="simple">
<li><p>Model the conditional probability using softmax of the dot product.</p>
<ul>
<li><p>Higher the dot product higher the probability and vice-versa.</p></li>
</ul>
</li>
</ul>
<div class="math notranslate nohighlight">
\[P(w_c|w_t;\theta) = \frac{e^{w_c.w_t}}{\sum\limits_{\substack{c' \in V}} e^{w_{c'}.w_t}}\]</div>
<ul class="simple">
<li><p>Substituting the conditional probability with the softmax of dot product:
$<span class="math notranslate nohighlight">\( \arg \max\limits_\theta \prod\limits_{(w_c,w_t) \in D} P(w_c|w_t;\theta) \approx \prod\limits_{(w_c,w_t) \in D} \frac{e^{w_c.w_t}}{\sum\limits_{\substack{c' \in V}} e^{w_{c'}.w_t}}\)</span>$</p></li>
<li><p>Assumption: Maximizing this objective on a large corpus will result in meaningful embeddings for all words in the vocabulary.</p></li>
</ul>
<p><strong>Main hyperparameters of the model</strong></p>
<ul class="simple">
<li><p>Dimensionality of the word vectors</p></li>
<li><p>Window size</p>
<ul>
<li><p>shorter window: more syntactic representation</p></li>
<li><p>longer window: more semantic representation</p></li>
<li><p>Mikolov et al. (2015) suggest setting this parameter in the range 5 to 20 for small training datasets and in the range 2 to 5 for large training datasets.</p></li>
</ul>
</li>
</ul>
<p><strong>(Optional) Parameters to learn</strong></p>
<ul class="simple">
<li><p>Given a corpus with vocabulary of size <span class="math notranslate nohighlight">\(V\)</span>, where a word <span class="math notranslate nohighlight">\(w_i\)</span> is identified by its index <span class="math notranslate nohighlight">\(i \in {1, ..., V}\)</span>, learn a vector representation for each <span class="math notranslate nohighlight">\(w_i\)</span> by predicting the words that appear in its context.</p></li>
<li><p>Learn the following parameters of the model</p>
<ul>
<li><p>Suppose <span class="math notranslate nohighlight">\(V = 10,000\)</span>, <span class="math notranslate nohighlight">\(d = 300\)</span>, the number of parameters to learn are 6,000,000!</p></li>
</ul>
</li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\theta = 
\begin{bmatrix} aardvark_t\\
                aback_t\\
                \dots\\
                zymurgi_t\\
                aardvark_c\\
                aback_c\\                
                \dots\\
                zymurgi_c\\                
\end{bmatrix} \in R^{2dV}
\end{split}\]</div>
<p><br><br><br><br></p>
<p><br><br><br><rb></p>
</section>
</section>
<section id="questions-for-you">
<h2>❓❓ Questions for you<a class="headerlink" href="#questions-for-you" title="Permalink to this heading">#</a></h2>
<section id="exercise-5-1-select-all-of-the-following-statements-which-are-true-iclicker">
<h3>Exercise 5.1 Select all of the following statements which are <strong>True</strong> (iClicker)<a class="headerlink" href="#exercise-5-1-select-all-of-the-following-statements-which-are-true-iclicker" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>(A) Word representation created by term-term co-occurrence matrix are long and sparse whereas the ones created by word2vec are short and dense.</p></li>
<li><p>(B) You could pass term-term co-occurrence matrix to <code class="docutils literal notranslate"><span class="pre">TruncatedSVD</span></code> or LSA to get short and dense representations.</p></li>
<li><p>(C) The word2vec algorithm does not require any manually labeled training data.</p></li>
<li><p>(D) When training a word2vec model, it is fine if we do poorly on the fake word prediction task because in the end we only care about the learned weights of the model.</p></li>
<li><p>(E) Given the following table (word 1, word 2) are more similar than (word 1, word 3) in terms of dot products.</p></li>
</ul>
<p><img alt="" src="../_images/similarity_question.png" /></p>
<!-- <img src="img/similarity_question.png" width="500" height="500"> --><p><br><br><br><br></p>
</section>
</section>
<section id="more-word2vec">
<h2>4. More word2vec<a class="headerlink" href="#more-word2vec" title="Permalink to this heading">#</a></h2>
<section id="skip-gram-demo-with-toy-data">
<h3>4.1 Skip-gram demo with toy data<a class="headerlink" href="#skip-gram-demo-with-toy-data" title="Permalink to this heading">#</a></h3>
<p><strong>For the purpose of your lab or quiz, you do not have to understand the code in this demo.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">toy_corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;drink mango juice&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink pineapple juice&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink apple juice&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink squeezed pineapple juice&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink squeezed mango juice&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink apple tea&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink mango tea&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink mango water&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink apple water&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink pineapple water&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink juice&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink water&quot;</span><span class="p">,</span>
    <span class="s2">&quot;drink tea&quot;</span><span class="p">,</span>
    <span class="s2">&quot;play hockey&quot;</span><span class="p">,</span>
    <span class="s2">&quot;play football&quot;</span><span class="p">,</span>
    <span class="s2">&quot;play piano&quot;</span><span class="p">,</span>
    <span class="s2">&quot;piano play&quot;</span><span class="p">,</span>
    <span class="s2">&quot;play hockey game&quot;</span><span class="p">,</span>
    <span class="s2">&quot;play football game&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sents</span> <span class="o">=</span> <span class="n">MyPreprocessor</span><span class="p">(</span><span class="n">toy_corpus</span><span class="p">)</span>  <span class="c1"># memory smart generator</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">CONTEXT_SIZE</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">word2vec_demo</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">get_vocab</span><span class="p">(</span><span class="n">sents</span><span class="p">)</span>
<span class="n">word2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
<span class="n">idx2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">w</span> <span class="k">for</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>

<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocab</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;piano&#39;,
 &#39;juice&#39;,
 &#39;tea&#39;,
 &#39;apple&#39;,
 &#39;pineapple&#39;,
 &#39;drink&#39;,
 &#39;hockey&#39;,
 &#39;game&#39;,
 &#39;football&#39;,
 &#39;play&#39;,
 &#39;water&#39;,
 &#39;mango&#39;,
 &#39;squeezed&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">idx_pairs</span> <span class="o">=</span> <span class="n">create_input_pairs</span><span class="p">(</span><span class="n">sents</span><span class="p">,</span> <span class="n">word2idx</span><span class="p">)</span>    
<span class="n">idx_pairs</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span> <span class="c1"># training examples</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 5, 11],
       [ 5,  1],
       [11,  5],
       [11,  1],
       [ 1,  5],
       [ 1, 11],
       [ 5,  4],
       [ 5,  1],
       [ 4,  5],
       [ 4,  1]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SkipgramModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">EMBEDDING_DIM</span><span class="p">)</span>
<span class="n">train_skipgram</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">idx_pairs</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">panel</span> <span class="k">as</span> <span class="nn">pn</span>
<span class="kn">from</span> <span class="nn">panel</span> <span class="kn">import</span> <span class="n">widgets</span>
<span class="kn">from</span> <span class="nn">panel.interact</span> <span class="kn">import</span> <span class="n">interact</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>

<span class="n">pn</span><span class="o">.</span><span class="n">extension</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>    
    <span class="k">return</span> <span class="n">plot_embeddings</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">idx_pairs</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">word2idx</span><span class="p">)</span>

<span class="c1">#interact(f, angle=widgets.IntSlider(start=0, end=182, step=1, value=0))</span>
<span class="n">interact</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="c1">#.embed(max_opts=200)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">(function(root) {
  function now() {
    return new Date();
  }

  var force = true;
  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');
  var reloading = false;
  var Bokeh = root.Bokeh;

  if (typeof (root._bokeh_timeout) === "undefined" || force) {
    root._bokeh_timeout = Date.now() + 5000;
    root._bokeh_failed_load = false;
  }

  function run_callbacks() {
    try {
      root._bokeh_onload_callbacks.forEach(function(callback) {
        if (callback != null)
          callback();
      });
    } finally {
      delete root._bokeh_onload_callbacks;
    }
    console.debug("Bokeh: all callbacks have finished");
  }

  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {
    if (css_urls == null) css_urls = [];
    if (js_urls == null) js_urls = [];
    if (js_modules == null) js_modules = [];
    if (js_exports == null) js_exports = {};

    root._bokeh_onload_callbacks.push(callback);

    if (root._bokeh_is_loading > 0) {
      console.debug("Bokeh: BokehJS is being loaded, scheduling callback at", now());
      return null;
    }
    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {
      run_callbacks();
      return null;
    }
    if (!reloading) {
      console.debug("Bokeh: BokehJS not loaded, scheduling load and callback at", now());
    }

    function on_load() {
      root._bokeh_is_loading--;
      if (root._bokeh_is_loading === 0) {
        console.debug("Bokeh: all BokehJS libraries/stylesheets loaded");
        run_callbacks()
      }
    }
    window._bokeh_on_load = on_load

    function on_error() {
      console.error("failed to load " + url);
    }

    var skip = [];
    if (window.requirejs) {
      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});
      require(["jspanel"], function(jsPanel) {
	window.jsPanel = jsPanel
	on_load()
      })
      require(["jspanel-modal"], function() {
	on_load()
      })
      require(["jspanel-tooltip"], function() {
	on_load()
      })
      require(["jspanel-hint"], function() {
	on_load()
      })
      require(["jspanel-layout"], function() {
	on_load()
      })
      require(["jspanel-contextmenu"], function() {
	on_load()
      })
      require(["jspanel-dock"], function() {
	on_load()
      })
      require(["gridstack"], function(GridStack) {
	window.GridStack = GridStack
	on_load()
      })
      require(["notyf"], function() {
	on_load()
      })
      root._bokeh_is_loading = css_urls.length + 9;
    } else {
      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;
    }

    var existing_stylesheets = []
    var links = document.getElementsByTagName('link')
    for (var i = 0; i < links.length; i++) {
      var link = links[i]
      if (link.href != null) {
	existing_stylesheets.push(link.href)
      }
    }
    for (var i = 0; i < css_urls.length; i++) {
      var url = css_urls[i];
      if (existing_stylesheets.indexOf(url) !== -1) {
	on_load()
	continue;
      }
      const element = document.createElement("link");
      element.onload = on_load;
      element.onerror = on_error;
      element.rel = "stylesheet";
      element.type = "text/css";
      element.href = url;
      console.debug("Bokeh: injecting link tag for BokehJS stylesheet: ", url);
      document.body.appendChild(element);
    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {
      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];
      for (var i = 0; i < urls.length; i++) {
        skip.push(urls[i])
      }
    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {
      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];
      for (var i = 0; i < urls.length; i++) {
        skip.push(urls[i])
      }
    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {
      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];
      for (var i = 0; i < urls.length; i++) {
        skip.push(urls[i])
      }
    }    var existing_scripts = []
    var scripts = document.getElementsByTagName('script')
    for (var i = 0; i < scripts.length; i++) {
      var script = scripts[i]
      if (script.src != null) {
	existing_scripts.push(script.src)
      }
    }
    for (var i = 0; i < js_urls.length; i++) {
      var url = js_urls[i];
      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {
	if (!window.requirejs) {
	  on_load();
	}
	continue;
      }
      var element = document.createElement('script');
      element.onload = on_load;
      element.onerror = on_error;
      element.async = false;
      element.src = url;
      console.debug("Bokeh: injecting script tag for BokehJS library: ", url);
      document.head.appendChild(element);
    }
    for (var i = 0; i < js_modules.length; i++) {
      var url = js_modules[i];
      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {
	if (!window.requirejs) {
	  on_load();
	}
	continue;
      }
      var element = document.createElement('script');
      element.onload = on_load;
      element.onerror = on_error;
      element.async = false;
      element.src = url;
      element.type = "module";
      console.debug("Bokeh: injecting script tag for BokehJS library: ", url);
      document.head.appendChild(element);
    }
    for (const name in js_exports) {
      var url = js_exports[name];
      if (skip.indexOf(url) >= 0 || root[name] != null) {
	if (!window.requirejs) {
	  on_load();
	}
	continue;
      }
      var element = document.createElement('script');
      element.onerror = on_error;
      element.async = false;
      element.type = "module";
      console.debug("Bokeh: injecting script tag for BokehJS library: ", url);
      element.textContent = `
      import ${name} from "${url}"
      window.${name} = ${name}
      window._bokeh_on_load()
      `
      document.head.appendChild(element);
    }
    if (!js_urls.length && !js_modules.length) {
      on_load()
    }
  };

  function inject_raw_css(css) {
    const element = document.createElement("style");
    element.appendChild(document.createTextNode(css));
    document.body.appendChild(element);
  }

  var js_urls = ["https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js", "https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js"];
  var js_modules = [];
  var js_exports = {};
  var css_urls = [];
  var inline_js = [    function(Bokeh) {
      Bokeh.set_log_level("info");
    },
function(Bokeh) {} // ensure no trailing comma for IE
  ];

  function run_inline_js() {
    if ((root.Bokeh !== undefined) || (force === true)) {
      for (var i = 0; i < inline_js.length; i++) {
	try {
          inline_js[i].call(root, root.Bokeh);
	} catch(e) {
	  if (!reloading) {
	    throw e;
	  }
	}
      }
      // Cache old bokeh versions
      if (Bokeh != undefined && !reloading) {
	var NewBokeh = root.Bokeh;
	if (Bokeh.versions === undefined) {
	  Bokeh.versions = new Map();
	}
	if (NewBokeh.version !== Bokeh.version) {
	  Bokeh.versions.set(NewBokeh.version, NewBokeh)
	}
	root.Bokeh = Bokeh;
      }} else if (Date.now() < root._bokeh_timeout) {
      setTimeout(run_inline_js, 100);
    } else if (!root._bokeh_failed_load) {
      console.log("Bokeh: BokehJS failed to load within specified timeout.");
      root._bokeh_failed_load = true;
    }
    root._bokeh_is_initializing = false
  }

  function load_or_wait() {
    // Implement a backoff loop that tries to ensure we do not load multiple
    // versions of Bokeh and its dependencies at the same time.
    // In recent versions we use the root._bokeh_is_initializing flag
    // to determine whether there is an ongoing attempt to initialize
    // bokeh, however for backward compatibility we also try to ensure
    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version
    // before older versions are fully initialized.
    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {
      root._bokeh_is_initializing = false;
      root._bokeh_onload_callbacks = undefined;
      console.log("Bokeh: BokehJS was loaded multiple times but one version failed to initialize.");
      load_or_wait();
    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === "undefined" && root._bokeh_onload_callbacks !== undefined)) {
      setTimeout(load_or_wait, 100);
    } else {
      root._bokeh_is_initializing = true
      root._bokeh_onload_callbacks = []
      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));
      if (!reloading && !bokeh_loaded) {
	root.Bokeh = undefined;
      }
      load_libs(css_urls, js_urls, js_modules, js_exports, function() {
	console.debug("Bokeh: BokehJS plotting callback run at", now());
	run_inline_js();
      });
    }
  }
  // Give older versions of the autoload script a head-start to ensure
  // they initialize before we start loading newer version.
  setTimeout(load_or_wait, 100)
}(window));</script><script type="application/javascript">
if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {
  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}
}


    function JupyterCommManager() {
    }

    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {
      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {
        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;
        comm_manager.register_target(comm_id, function(comm) {
          comm.on_msg(msg_handler);
        });
      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {
        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {
          comm.onMsg = msg_handler;
        });
      } else if (typeof google != 'undefined' && google.colab.kernel != null) {
        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {
          var messages = comm.messages[Symbol.asyncIterator]();
          function processIteratorResult(result) {
            var message = result.value;
            console.log(message)
            var content = {data: message.data, comm_id};
            var buffers = []
            for (var buffer of message.buffers || []) {
              buffers.push(new DataView(buffer))
            }
            var metadata = message.metadata || {};
            var msg = {content, buffers, metadata}
            msg_handler(msg);
            return messages.next().then(processIteratorResult);
          }
          return messages.next().then(processIteratorResult);
        })
      }
    }

    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {
      if (comm_id in window.PyViz.comms) {
        return window.PyViz.comms[comm_id];
      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {
        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;
        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);
        if (msg_handler) {
          comm.on_msg(msg_handler);
        }
      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {
        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);
        comm.open();
        if (msg_handler) {
          comm.onMsg = msg_handler;
        }
      } else if (typeof google != 'undefined' && google.colab.kernel != null) {
        var comm_promise = google.colab.kernel.comms.open(comm_id)
        comm_promise.then((comm) => {
          window.PyViz.comms[comm_id] = comm;
          if (msg_handler) {
            var messages = comm.messages[Symbol.asyncIterator]();
            function processIteratorResult(result) {
              var message = result.value;
              var content = {data: message.data};
              var metadata = message.metadata || {comm_id};
              var msg = {content, metadata}
              msg_handler(msg);
              return messages.next().then(processIteratorResult);
            }
            return messages.next().then(processIteratorResult);
          }
        }) 
        var sendClosure = (data, metadata, buffers, disposeOnDone) => {
          return comm_promise.then((comm) => {
            comm.send(data, metadata, buffers, disposeOnDone);
          });
        };
        var comm = {
          send: sendClosure
        };
      }
      window.PyViz.comms[comm_id] = comm;
      return comm;
    }
    window.PyViz.comm_manager = new JupyterCommManager();
    


var JS_MIME_TYPE = 'application/javascript';
var HTML_MIME_TYPE = 'text/html';
var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';
var CLASS_NAME = 'output';

/**
 * Render data to the DOM node
 */
function render(props, node) {
  var div = document.createElement("div");
  var script = document.createElement("script");
  node.appendChild(div);
  node.appendChild(script);
}

/**
 * Handle when a new output is added
 */
function handle_add_output(event, handle) {
  var output_area = handle.output_area;
  var output = handle.output;
  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {
    return
  }
  var id = output.metadata[EXEC_MIME_TYPE]["id"];
  var toinsert = output_area.element.find("." + CLASS_NAME.split(' ')[0]);
  if (id !== undefined) {
    var nchildren = toinsert.length;
    var html_node = toinsert[nchildren-1].children[0];
    html_node.innerHTML = output.data[HTML_MIME_TYPE];
    var scripts = [];
    var nodelist = html_node.querySelectorAll("script");
    for (var i in nodelist) {
      if (nodelist.hasOwnProperty(i)) {
        scripts.push(nodelist[i])
      }
    }

    scripts.forEach( function (oldScript) {
      var newScript = document.createElement("script");
      var attrs = [];
      var nodemap = oldScript.attributes;
      for (var j in nodemap) {
        if (nodemap.hasOwnProperty(j)) {
          attrs.push(nodemap[j])
        }
      }
      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });
      newScript.appendChild(document.createTextNode(oldScript.innerHTML));
      oldScript.parentNode.replaceChild(newScript, oldScript);
    });
    if (JS_MIME_TYPE in output.data) {
      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];
    }
    output_area._hv_plot_id = id;
    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {
      window.PyViz.plot_index[id] = Bokeh.index[id];
    } else {
      window.PyViz.plot_index[id] = null;
    }
  } else if (output.metadata[EXEC_MIME_TYPE]["server_id"] !== undefined) {
    var bk_div = document.createElement("div");
    bk_div.innerHTML = output.data[HTML_MIME_TYPE];
    var script_attrs = bk_div.children[0].attributes;
    for (var i = 0; i < script_attrs.length; i++) {
      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);
    }
    // store reference to server id on output_area
    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE]["server_id"];
  }
}

/**
 * Handle when an output is cleared or removed
 */
function handle_clear_output(event, handle) {
  var id = handle.cell.output_area._hv_plot_id;
  var server_id = handle.cell.output_area._bokeh_server_id;
  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }
  var comm = window.PyViz.comm_manager.get_client_comm("hv-extension-comm", "hv-extension-comm", function () {});
  if (server_id !== null) {
    comm.send({event_type: 'server_delete', 'id': server_id});
    return;
  } else if (comm !== null) {
    comm.send({event_type: 'delete', 'id': id});
  }
  delete PyViz.plot_index[id];
  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {
    var doc = window.Bokeh.index[id].model.document
    doc.clear();
    const i = window.Bokeh.documents.indexOf(doc);
    if (i > -1) {
      window.Bokeh.documents.splice(i, 1);
    }
  }
}

/**
 * Handle kernel restart event
 */
function handle_kernel_cleanup(event, handle) {
  delete PyViz.comms["hv-extension-comm"];
  window.PyViz.plot_index = {}
}

/**
 * Handle update_display_data messages
 */
function handle_update_output(event, handle) {
  handle_clear_output(event, {cell: {output_area: handle.output_area}})
  handle_add_output(event, handle)
}

function register_renderer(events, OutputArea) {
  function append_mime(data, metadata, element) {
    // create a DOM node to render to
    var toinsert = this.create_output_subarea(
    metadata,
    CLASS_NAME,
    EXEC_MIME_TYPE
    );
    this.keyboard_manager.register_events(toinsert);
    // Render to node
    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};
    render(props, toinsert[0]);
    element.append(toinsert);
    return toinsert
  }

  events.on('output_added.OutputArea', handle_add_output);
  events.on('output_updated.OutputArea', handle_update_output);
  events.on('clear_output.CodeCell', handle_clear_output);
  events.on('delete.Cell', handle_clear_output);
  events.on('kernel_ready.Kernel', handle_kernel_cleanup);

  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {
    safe: true,
    index: 0
  });
}

if (window.Jupyter !== undefined) {
  try {
    var events = require('base/js/events');
    var OutputArea = require('notebook/js/outputarea').OutputArea;
    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {
      register_renderer(events, OutputArea);
    }
  } catch(err) {
  }
}
</script><div class="output text_html"><style>*[data-root-id],
*[data-root-id] > * {
  box-sizing: border-box;
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));
}

/* Override VSCode background color */
.cell-output-ipywidget-background:has(
    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]
  ),
.cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {
  background-color: transparent !important;
}
</style></div><div class="output text_html"><div id='8c70989c-5f6f-4dd8-9a10-f7dd89e8d03f'>
  <div id="e7071988-5275-4c2f-bb46-b0cad3495d05" data-root-id="8c70989c-5f6f-4dd8-9a10-f7dd89e8d03f" style="display: contents;"></div>
</div>
<script type="application/javascript">(function(root) {
  var docs_json = {"ed256e05-9118-43f0-9cec-f7ff32c5606d":{"version":"3.3.4","title":"Bokeh Application","roots":[{"type":"object","name":"panel.models.browser.BrowserInfo","id":"8c70989c-5f6f-4dd8-9a10-f7dd89e8d03f"},{"type":"object","name":"panel.models.comm_manager.CommManager","id":"6e17b2aa-4df9-4998-b768-113b8edd63d2","attributes":{"plot_id":"8c70989c-5f6f-4dd8-9a10-f7dd89e8d03f","comm_id":"c5feb2996df24c83bb183ef581fa1b20","client_comm_id":"2afc53dec9df4e9b8cf43bf674052c91"}}],"defs":[{"type":"model","name":"ReactiveHTML1"},{"type":"model","name":"FlexBox1","properties":[{"name":"align_content","kind":"Any","default":"flex-start"},{"name":"align_items","kind":"Any","default":"flex-start"},{"name":"flex_direction","kind":"Any","default":"row"},{"name":"flex_wrap","kind":"Any","default":"wrap"},{"name":"justify_content","kind":"Any","default":"flex-start"}]},{"type":"model","name":"FloatPanel1","properties":[{"name":"config","kind":"Any","default":{"type":"map"}},{"name":"contained","kind":"Any","default":true},{"name":"position","kind":"Any","default":"right-top"},{"name":"offsetx","kind":"Any","default":null},{"name":"offsety","kind":"Any","default":null},{"name":"theme","kind":"Any","default":"primary"},{"name":"status","kind":"Any","default":"normalized"}]},{"type":"model","name":"GridStack1","properties":[{"name":"mode","kind":"Any","default":"warn"},{"name":"ncols","kind":"Any","default":null},{"name":"nrows","kind":"Any","default":null},{"name":"allow_resize","kind":"Any","default":true},{"name":"allow_drag","kind":"Any","default":true},{"name":"state","kind":"Any","default":[]}]},{"type":"model","name":"drag1","properties":[{"name":"slider_width","kind":"Any","default":5},{"name":"slider_color","kind":"Any","default":"black"},{"name":"value","kind":"Any","default":50}]},{"type":"model","name":"click1","properties":[{"name":"terminal_output","kind":"Any","default":""},{"name":"debug_name","kind":"Any","default":""},{"name":"clears","kind":"Any","default":0}]},{"type":"model","name":"copy_to_clipboard1","properties":[{"name":"fill","kind":"Any","default":"none"},{"name":"value","kind":"Any","default":null}]},{"type":"model","name":"FastWrapper1","properties":[{"name":"object","kind":"Any","default":null},{"name":"style","kind":"Any","default":null}]},{"type":"model","name":"NotificationAreaBase1","properties":[{"name":"js_events","kind":"Any","default":{"type":"map"}},{"name":"position","kind":"Any","default":"bottom-right"},{"name":"_clear","kind":"Any","default":0}]},{"type":"model","name":"NotificationArea1","properties":[{"name":"js_events","kind":"Any","default":{"type":"map"}},{"name":"notifications","kind":"Any","default":[]},{"name":"position","kind":"Any","default":"bottom-right"},{"name":"_clear","kind":"Any","default":0},{"name":"types","kind":"Any","default":[{"type":"map","entries":[["type","warning"],["background","#ffc107"],["icon",{"type":"map","entries":[["className","fas fa-exclamation-triangle"],["tagName","i"],["color","white"]]}]]},{"type":"map","entries":[["type","info"],["background","#007bff"],["icon",{"type":"map","entries":[["className","fas fa-info-circle"],["tagName","i"],["color","white"]]}]]}]}]},{"type":"model","name":"Notification","properties":[{"name":"background","kind":"Any","default":null},{"name":"duration","kind":"Any","default":3000},{"name":"icon","kind":"Any","default":null},{"name":"message","kind":"Any","default":""},{"name":"notification_type","kind":"Any","default":null},{"name":"_destroyed","kind":"Any","default":false}]},{"type":"model","name":"TemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]},{"type":"model","name":"BootstrapTemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]},{"type":"model","name":"MaterialTemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]}]}};
  var render_items = [{"docid":"ed256e05-9118-43f0-9cec-f7ff32c5606d","roots":{"8c70989c-5f6f-4dd8-9a10-f7dd89e8d03f":"e7071988-5275-4c2f-bb46-b0cad3495d05"},"root_ids":["8c70989c-5f6f-4dd8-9a10-f7dd89e8d03f"]}];
  var docs = Object.values(docs_json)
  if (!docs) {
    return
  }
  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')
  function embed_document(root) {
    var Bokeh = get_bokeh(root)
    Bokeh.embed.embed_items_notebook(docs_json, render_items);
    for (const render_item of render_items) {
      for (const root_id of render_item.root_ids) {
	const id_el = document.getElementById(root_id)
	if (id_el.children.length && (id_el.children[0].className === 'bk-root')) {
	  const root_el = id_el.children[0]
	  root_el.id = root_el.id + '-rendered'
	}
      }
    }
  }
  function get_bokeh(root) {
    if (root.Bokeh === undefined) {
      return null
    } else if (root.Bokeh.version !== py_version) {
      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {
	return null
      }
      return root.Bokeh.versions.get(py_version);
    } else if (root.Bokeh.version === py_version) {
      return root.Bokeh
    }
    return null
  }
  function is_loaded(root) {
    var Bokeh = get_bokeh(root)
    return (Bokeh != null && Bokeh.Panel !== undefined)
  }
  if (is_loaded(root)) {
    embed_document(root);
  } else {
    var attempts = 0;
    var timer = setInterval(function(root) {
      if (is_loaded(root)) {
        clearInterval(timer);
        embed_document(root);
      } else if (document.readyState == "complete") {
        attempts++;
        if (attempts > 200) {
          clearInterval(timer);
	  var Bokeh = get_bokeh(root)
	  if (Bokeh == null || Bokeh.Panel == null) {
            console.warn("Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing");
	  } else {
	    console.warn("Panel: WARNING: Attempting to render but not all required libraries could be resolved.")
	    embed_document(root)
	  }
        }
      }
    }, 25, root)
  }
})(window);</script></div><div class="output text_html"><div id='90920467-d36f-4899-8f12-2d496e2ce38f'>
  <div id="dcf22597-1e5b-4e89-82db-88909f8750d8" data-root-id="90920467-d36f-4899-8f12-2d496e2ce38f" style="display: contents;"></div>
</div>
<script type="application/javascript">(function(root) {
  var docs_json = {"0372bee8-4baf-4349-9fbe-772561ed740a":{"version":"3.3.4","title":"Bokeh Application","roots":[{"type":"object","name":"panel.models.layout.Column","id":"90920467-d36f-4899-8f12-2d496e2ce38f","attributes":{"name":"Column00119","stylesheets":["\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\n  background-image: url(\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\");\n  background-size: auto calc(min(50%, 400px));\n}",{"type":"object","name":"ImportedStyleSheet","id":"2c2e3239-31bf-4cce-a22b-7f079d3a3df2","attributes":{"url":"https://cdn.holoviz.org/panel/1.3.8/dist/css/loading.css"}},{"type":"object","name":"ImportedStyleSheet","id":"479aa1a6-74b5-4975-8090-f2408d553157","attributes":{"url":"https://cdn.holoviz.org/panel/1.3.8/dist/css/listpanel.css"}},{"type":"object","name":"ImportedStyleSheet","id":"0fad62a6-e546-49b1-a0f4-37ed6d009db6","attributes":{"url":"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/default.css"}},{"type":"object","name":"ImportedStyleSheet","id":"61e210a8-bb3d-4737-80c0-9c67cecfb7c7","attributes":{"url":"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/native.css"}}],"margin":0,"align":"start","children":[{"type":"object","name":"panel.models.layout.Column","id":"0dd12600-00de-4f82-a6fd-2d1c7d145fda","attributes":{"name":"Column00124","stylesheets":["\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\n  background-image: url(\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\");\n  background-size: auto calc(min(50%, 400px));\n}",{"id":"2c2e3239-31bf-4cce-a22b-7f079d3a3df2"},{"id":"479aa1a6-74b5-4975-8090-f2408d553157"},{"id":"0fad62a6-e546-49b1-a0f4-37ed6d009db6"},{"id":"61e210a8-bb3d-4737-80c0-9c67cecfb7c7"}],"margin":0,"align":"start","children":[{"type":"object","name":"Slider","id":"3ff30394-f7ed-4f68-abb9-7eca8a65b137","attributes":{"stylesheets":["\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\n  background-image: url(\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\");\n  background-size: auto calc(min(50%, 400px));\n}",{"id":"2c2e3239-31bf-4cce-a22b-7f079d3a3df2"},{"id":"0fad62a6-e546-49b1-a0f4-37ed6d009db6"},{"id":"61e210a8-bb3d-4737-80c0-9c67cecfb7c7"}],"margin":[5,10],"align":"start","start":0,"end":1000,"value":0,"step":100}}]}},{"type":"object","name":"Row","id":"978c3fe7-0f25-466b-ac77-9892aa91d204","attributes":{"name":"Row00123","stylesheets":["\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\n  background-image: url(\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\");\n  background-size: auto calc(min(50%, 400px));\n}",{"id":"2c2e3239-31bf-4cce-a22b-7f079d3a3df2"},{"id":"479aa1a6-74b5-4975-8090-f2408d553157"},{"id":"0fad62a6-e546-49b1-a0f4-37ed6d009db6"},{"id":"61e210a8-bb3d-4737-80c0-9c67cecfb7c7"}],"margin":0,"align":"start","children":[{"type":"object","name":"panel.models.markup.HTML","id":"040e0922-e6ee-455f-ad26-36aff8da39c3","attributes":{"stylesheets":["\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\n  background-image: url(\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\");\n  background-size: auto calc(min(50%, 400px));\n}",{"id":"2c2e3239-31bf-4cce-a22b-7f079d3a3df2"},{"id":"0fad62a6-e546-49b1-a0f4-37ed6d009db6"},{"id":"61e210a8-bb3d-4737-80c0-9c67cecfb7c7"}],"width":864,"height":576,"min_width":864,"min_height":576,"margin":[5,10],"align":"start","text":"&lt;img src=&quot;data:image/png;base64,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&quot;  style=&quot;max-width: 100%; max-height: 100%; object-fit: contain; width: 864px; height: 576px;&quot;&gt;&lt;/img&gt;"}}]}}]}},{"type":"object","name":"panel.models.comm_manager.CommManager","id":"feef3280-6e33-4c4e-bedf-0cd7f1bcac80","attributes":{"plot_id":"90920467-d36f-4899-8f12-2d496e2ce38f","comm_id":"fff249f013ed48ef9f8af8d21fb1329b","client_comm_id":"aaf963baff594275bcd4bc5d0d2bb854"}}],"defs":[{"type":"model","name":"ReactiveHTML1"},{"type":"model","name":"FlexBox1","properties":[{"name":"align_content","kind":"Any","default":"flex-start"},{"name":"align_items","kind":"Any","default":"flex-start"},{"name":"flex_direction","kind":"Any","default":"row"},{"name":"flex_wrap","kind":"Any","default":"wrap"},{"name":"justify_content","kind":"Any","default":"flex-start"}]},{"type":"model","name":"FloatPanel1","properties":[{"name":"config","kind":"Any","default":{"type":"map"}},{"name":"contained","kind":"Any","default":true},{"name":"position","kind":"Any","default":"right-top"},{"name":"offsetx","kind":"Any","default":null},{"name":"offsety","kind":"Any","default":null},{"name":"theme","kind":"Any","default":"primary"},{"name":"status","kind":"Any","default":"normalized"}]},{"type":"model","name":"GridStack1","properties":[{"name":"mode","kind":"Any","default":"warn"},{"name":"ncols","kind":"Any","default":null},{"name":"nrows","kind":"Any","default":null},{"name":"allow_resize","kind":"Any","default":true},{"name":"allow_drag","kind":"Any","default":true},{"name":"state","kind":"Any","default":[]}]},{"type":"model","name":"drag1","properties":[{"name":"slider_width","kind":"Any","default":5},{"name":"slider_color","kind":"Any","default":"black"},{"name":"value","kind":"Any","default":50}]},{"type":"model","name":"click1","properties":[{"name":"terminal_output","kind":"Any","default":""},{"name":"debug_name","kind":"Any","default":""},{"name":"clears","kind":"Any","default":0}]},{"type":"model","name":"copy_to_clipboard1","properties":[{"name":"fill","kind":"Any","default":"none"},{"name":"value","kind":"Any","default":null}]},{"type":"model","name":"FastWrapper1","properties":[{"name":"object","kind":"Any","default":null},{"name":"style","kind":"Any","default":null}]},{"type":"model","name":"NotificationAreaBase1","properties":[{"name":"js_events","kind":"Any","default":{"type":"map"}},{"name":"position","kind":"Any","default":"bottom-right"},{"name":"_clear","kind":"Any","default":0}]},{"type":"model","name":"NotificationArea1","properties":[{"name":"js_events","kind":"Any","default":{"type":"map"}},{"name":"notifications","kind":"Any","default":[]},{"name":"position","kind":"Any","default":"bottom-right"},{"name":"_clear","kind":"Any","default":0},{"name":"types","kind":"Any","default":[{"type":"map","entries":[["type","warning"],["background","#ffc107"],["icon",{"type":"map","entries":[["className","fas fa-exclamation-triangle"],["tagName","i"],["color","white"]]}]]},{"type":"map","entries":[["type","info"],["background","#007bff"],["icon",{"type":"map","entries":[["className","fas fa-info-circle"],["tagName","i"],["color","white"]]}]]}]}]},{"type":"model","name":"Notification","properties":[{"name":"background","kind":"Any","default":null},{"name":"duration","kind":"Any","default":3000},{"name":"icon","kind":"Any","default":null},{"name":"message","kind":"Any","default":""},{"name":"notification_type","kind":"Any","default":null},{"name":"_destroyed","kind":"Any","default":false}]},{"type":"model","name":"TemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]},{"type":"model","name":"BootstrapTemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]},{"type":"model","name":"MaterialTemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]}]}};
  var render_items = [{"docid":"0372bee8-4baf-4349-9fbe-772561ed740a","roots":{"90920467-d36f-4899-8f12-2d496e2ce38f":"dcf22597-1e5b-4e89-82db-88909f8750d8"},"root_ids":["90920467-d36f-4899-8f12-2d496e2ce38f"]}];
  var docs = Object.values(docs_json)
  if (!docs) {
    return
  }
  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')
  function embed_document(root) {
    var Bokeh = get_bokeh(root)
    Bokeh.embed.embed_items_notebook(docs_json, render_items);
    for (const render_item of render_items) {
      for (const root_id of render_item.root_ids) {
	const id_el = document.getElementById(root_id)
	if (id_el.children.length && (id_el.children[0].className === 'bk-root')) {
	  const root_el = id_el.children[0]
	  root_el.id = root_el.id + '-rendered'
	}
      }
    }
  }
  function get_bokeh(root) {
    if (root.Bokeh === undefined) {
      return null
    } else if (root.Bokeh.version !== py_version) {
      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {
	return null
      }
      return root.Bokeh.versions.get(py_version);
    } else if (root.Bokeh.version === py_version) {
      return root.Bokeh
    }
    return null
  }
  function is_loaded(root) {
    var Bokeh = get_bokeh(root)
    return (Bokeh != null && Bokeh.Panel !== undefined)
  }
  if (is_loaded(root)) {
    embed_document(root);
  } else {
    var attempts = 0;
    var timer = setInterval(function(root) {
      if (is_loaded(root)) {
        clearInterval(timer);
        embed_document(root);
      } else if (document.readyState == "complete") {
        attempts++;
        if (attempts > 200) {
          clearInterval(timer);
	  var Bokeh = get_bokeh(root)
	  if (Bokeh == null || Bokeh.Panel == null) {
            console.warn("Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing");
	  } else {
	    console.warn("Panel: WARNING: Attempting to render but not all required libraries could be resolved.")
	    embed_document(root)
	  }
        }
      }
    }, 25, root)
  }
})(window);</script></div></div>
</div>
<p><br><br><br><br></p>
<p><strong>Skip-gram before the weights are trained</strong>
<a class="reference internal" href="../_images/word2vec-toy-epochs0.png"><img alt="../_images/word2vec-toy-epochs0.png" src="../_images/word2vec-toy-epochs0.png" style="width: 1000px; height: 1000px;" /></a></p>
<!-- <center>
<img src="img/word2vec-toy-epochs0.png" width="1000" height="1000">
</center>     --><p><strong>Skip-gram after 900 epochs</strong></p>
<a class="reference internal image-reference" href="../_images/word2vec-toy-epochs900.png"><img alt="../_images/word2vec-toy-epochs900.png" src="../_images/word2vec-toy-epochs900.png" style="width: 1000px; height: 1000px;" /></a>
<!-- <center>
<img src="img/word2vec-toy-epochs900.png" width="1000" height="1000">
</center>     --></section>
<section id="training-word2vec-embeddings">
<h3>4.2 Training word2vec embeddings<a class="headerlink" href="#training-word2vec-embeddings" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://code.google.com/archive/p/word2vec/">Original C code</a></p></li>
<li><p><a class="reference external" href="https://github.com/tmikolov/word2vec">GitHub version of the code</a></p></li>
<li><p><a class="reference external" href="https://radimrehurek.com/gensim/">Gensim</a>, an open source Python library that provides a Python interface for word2vec family of algorithms</p></li>
</ul>
<p>You can install it as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="n">conda</span> <span class="n">activate</span> <span class="mi">563</span>
<span class="o">&gt;</span> <span class="n">conda</span> <span class="n">install</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span><span class="p">::</span><span class="n">gensim</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;say&quot;</span><span class="p">,</span> <span class="s2">&quot;meow&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;dog&quot;</span><span class="p">,</span> <span class="s2">&quot;say&quot;</span><span class="p">,</span> <span class="s2">&quot;woof&quot;</span><span class="p">]]</span>
<span class="n">sentences</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;cat&#39;, &#39;say&#39;, &#39;meow&#39;], [&#39;dog&#39;, &#39;say&#39;, &#39;woof&#39;]]
</pre></div>
</div>
</div>
</div>
<p>We need a corpus to be preprocessed and stored as</p>
<ul class="simple">
<li><p>A list of lists.</p></li>
<li><p>Each inner list corresponds to a sequence of tokens from a sentence. In other words, each sentence is tokenized and stored as a list of tokens.</p></li>
</ul>
<p>Let’s look at the word vector of the word <em>cat</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># train word2vec model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="s2">&quot;cat&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.0960355 ,  0.05007293, -0.08759586, -0.04391825, -0.000351  ,
       -0.00296181, -0.0766124 ,  0.09614743,  0.04982058,  0.09233143],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>What’s the most similar word to the word <em>cat</em>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s2">&quot;cat&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;say&#39;, -0.22418658435344696),
 (&#39;dog&#39;, -0.3207966387271881),
 (&#39;meow&#39;, -0.36627137660980225),
 (&#39;woof&#39;, -0.5381841659545898)]
</pre></div>
</div>
</div>
</div>
<p>Let’s try it out on our small wiki corpus.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>709
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Machu Picchu is a 15th-century Inca citadel located in the Eastern Cordillera of southern Peru on a 2,430-meter (7,970 ft) mountain ridge.&#39;,
 &#39;Often referred to as the &quot;Lost City of the Incas&quot;, it is the most familiar icon of the Inca Empire.&#39;,
 &#39;It is located in the Machupicchu District within Urubamba Province above the Sacred Valley, which is 80 kilometers (50 mi) northwest of Cusco.&#39;,
 &#39;The Urubamba River flows past it, cutting through the Cordillera and creating a canyon with a tropical mountain climate.&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sents</span> <span class="o">=</span> <span class="n">MyPreprocessor</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">wiki_model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">sents</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wiki_model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="s2">&quot;tree&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.00726288, -0.00653676, -0.00611133,  0.00270797,  0.0062954 ,
       -0.01246749,  0.00360739,  0.01890011, -0.00831644, -0.00525167],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wiki_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s2">&quot;tree&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;ft&#39;, 0.5620871186256409),
 (&#39;redwood&#39;, 0.5433863401412964),
 (&#39;state&#39;, 0.49551403522491455),
 (&#39;trees&#39;, 0.49252673983573914),
 (&#39;picchu&#39;, 0.4924555718898773),
 (&#39;parliament&#39;, 0.4915319085121155),
 (&#39;provinces&#39;, 0.4913058280944824),
 (&#39;constitution&#39;, 0.4784410297870636),
 (&#39;president&#39;, 0.45981258153915405),
 (&#39;also&#39;, 0.4576851427555084)]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This is good. But if you want good and meaningful representations of words you need to train models on a large corpus such as the whole Wikipedia, which is computationally intensive.</p></li>
<li><p>So instead of training our own models, we use the <strong>pre-trained embeddings</strong>. These are the word embeddings people have trained embeddings on huge corpora and made them available for us to use.</p></li>
</ul>
<p>Let’s try out Google news pre-trained word vectors.</p>
</section>
<section id="pre-trained-embeddings">
<h3>4.3 Pre-trained embeddings<a class="headerlink" href="#pre-trained-embeddings" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Training embeddings is computationally expensive</p></li>
<li><p>For typical corpora, the vocabulary size is greater than 100,000.</p></li>
<li><p>If the size of embeddings is 300, the number of parameters of the model is <span class="math notranslate nohighlight">\(2 \times 30,000,000\)</span>.</p></li>
<li><p>So people have trained embeddings on huge corpora and made them available.</p></li>
</ul>
<p>A number of pre-trained word embeddings are available. The most popular ones are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://code.google.com/archive/p/word2vec/">word2vec</a></p>
<ul>
<li><p>trained on several corpora using the word2vec algorithm</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://wikipedia2vec.github.io/wikipedia2vec/pretrained/">wikipedia2vec</a></p>
<ul>
<li><p>pretrained embeddings for 12 languages</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://nlp.stanford.edu/projects/glove/">GloVe</a></p>
<ul>
<li><p>trained using <a class="reference external" href="https://nlp.stanford.edu/pubs/glove.pdf">the GloVe algorithm</a></p></li>
<li><p>published by Stanford University</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://fasttext.cc/docs/en/pretrained-vectors.html">fastText pre-trained embeddings for 294 languages</a></p>
<ul>
<li><p>trained using <a class="reference external" href="http://aclweb.org/anthology/Q17-1010">the fastText algorithm</a></p></li>
<li><p>published by Facebook</p></li>
</ul>
</li>
</ul>
<p>Let’s try Google News pre-trained embeddings.</p>
<ul class="simple">
<li><p>You can download pre-trained embeddings from their original source.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Gensim</span></code> provides an api to conveniently load them.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">google_news_vectors</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;word2vec-google-news-300&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="success-of-word2vec">
<h3>4.4 Success of word2vec<a class="headerlink" href="#success-of-word2vec" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>This analogy example often comes up when people talk about word2vec, which was used by the authors of this method.</p></li>
<li><p><strong>MAN : KING :: WOMAN : ?</strong></p>
<ul>
<li><p>What is the word that is similar to <strong>WOMAN</strong> in the same sense as <strong>KING</strong> is similar to <strong>MAN</strong>?</p></li>
</ul>
</li>
<li><p>Perform a simple algebraic operations with the vector representation of words.
<span class="math notranslate nohighlight">\(\vec{X} = \vec{\text{KING}} − \vec{\text{MAN}} + \vec{\text{WOMAN}}\)</span></p></li>
<li><p>Search in the vector space for the word closest to <span class="math notranslate nohighlight">\(\vec{X}\)</span> measured by cosine distance.</p></li>
</ul>
<!-- ![](img/word_analogies1.png) -->
<center>
<img src="img/word_analogies1.png" width="400" height="400">
</center>
<p>(Credit: Mikolov et al. 2013)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">analogy</span><span class="p">(</span><span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">,</span> <span class="n">word3</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">google_news_vectors</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns analogy word using the given model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    --------------</span>
<span class="sd">    word1 : (str)</span>
<span class="sd">        word1 in the analogy relation</span>
<span class="sd">    word2 : (str)</span>
<span class="sd">        word2 in the analogy relation</span>
<span class="sd">    word3 : (str)</span>
<span class="sd">        word3 in the analogy relation</span>
<span class="sd">    model :</span>
<span class="sd">        word embedding model</span>

<span class="sd">    Returns</span>
<span class="sd">    ---------------</span>
<span class="sd">        pd.dataframe</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> : </span><span class="si">%s</span><span class="s2"> :: </span><span class="si">%s</span><span class="s2"> : ?&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">,</span> <span class="n">word3</span><span class="p">))</span>
    <span class="n">sim_words</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="n">word3</span><span class="p">,</span> <span class="n">word2</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="n">word1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">sim_words</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Analogy word&quot;</span><span class="p">,</span> <span class="s2">&quot;Score&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analogy</span><span class="p">(</span><span class="s2">&quot;man&quot;</span><span class="p">,</span> <span class="s2">&quot;king&quot;</span><span class="p">,</span> <span class="s2">&quot;woman&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>man : king :: woman : ?
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Analogy word</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>queen</td>
      <td>0.711819</td>
    </tr>
    <tr>
      <th>1</th>
      <td>monarch</td>
      <td>0.618967</td>
    </tr>
    <tr>
      <th>2</th>
      <td>princess</td>
      <td>0.590243</td>
    </tr>
    <tr>
      <th>3</th>
      <td>crown_prince</td>
      <td>0.549946</td>
    </tr>
    <tr>
      <th>4</th>
      <td>prince</td>
      <td>0.537732</td>
    </tr>
    <tr>
      <th>5</th>
      <td>kings</td>
      <td>0.523684</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Queen_Consort</td>
      <td>0.523595</td>
    </tr>
    <tr>
      <th>7</th>
      <td>queens</td>
      <td>0.518113</td>
    </tr>
    <tr>
      <th>8</th>
      <td>sultan</td>
      <td>0.509859</td>
    </tr>
    <tr>
      <th>9</th>
      <td>monarchy</td>
      <td>0.508741</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analogy</span><span class="p">(</span><span class="s2">&quot;Montreal&quot;</span><span class="p">,</span> <span class="s2">&quot;Canadiens&quot;</span><span class="p">,</span> <span class="s2">&quot;Vancouver&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Montreal : Canadiens :: Vancouver : ?
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Analogy word</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Canucks</td>
      <td>0.821327</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Vancouver_Canucks</td>
      <td>0.750401</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Calgary_Flames</td>
      <td>0.705471</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Leafs</td>
      <td>0.695783</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Maple_Leafs</td>
      <td>0.691617</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Thrashers</td>
      <td>0.687503</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Avs</td>
      <td>0.681716</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Sabres</td>
      <td>0.665307</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Blackhawks</td>
      <td>0.664625</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Habs</td>
      <td>0.661023</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analogy</span><span class="p">(</span><span class="s2">&quot;Toronto&quot;</span><span class="p">,</span> <span class="s2">&quot;UofT&quot;</span><span class="p">,</span> <span class="s2">&quot;Vancouver&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Toronto : UofT :: Vancouver : ?
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Analogy word</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SFU</td>
      <td>0.579245</td>
    </tr>
    <tr>
      <th>1</th>
      <td>UVic</td>
      <td>0.576921</td>
    </tr>
    <tr>
      <th>2</th>
      <td>UBC</td>
      <td>0.571431</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Simon_Fraser</td>
      <td>0.543464</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Langara_College</td>
      <td>0.541347</td>
    </tr>
    <tr>
      <th>5</th>
      <td>UVIC</td>
      <td>0.520495</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Grant_MacEwan</td>
      <td>0.517273</td>
    </tr>
    <tr>
      <th>7</th>
      <td>UFV</td>
      <td>0.514150</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Ubyssey</td>
      <td>0.510421</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Kwantlen</td>
      <td>0.503807</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analogy</span><span class="p">(</span><span class="s2">&quot;Gauss&quot;</span><span class="p">,</span> <span class="s2">&quot;mathematician&quot;</span><span class="p">,</span> <span class="s2">&quot;Bob_Dylan&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Gauss : mathematician :: Bob_Dylan : ?
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Analogy word</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>singer_songwriter_Bob_Dylan</td>
      <td>0.520782</td>
    </tr>
    <tr>
      <th>1</th>
      <td>poet</td>
      <td>0.501191</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Pete_Seeger</td>
      <td>0.497143</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Joan_Baez</td>
      <td>0.492307</td>
    </tr>
    <tr>
      <th>4</th>
      <td>sitarist_Ravi_Shankar</td>
      <td>0.491968</td>
    </tr>
    <tr>
      <th>5</th>
      <td>bluesman</td>
      <td>0.490930</td>
    </tr>
    <tr>
      <th>6</th>
      <td>jazz_musician</td>
      <td>0.489593</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Joni_Mitchell</td>
      <td>0.487740</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Billie_Holiday</td>
      <td>0.486664</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Johnny_Cash</td>
      <td>0.485722</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analogy</span><span class="p">(</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span> <span class="s2">&quot;pizza&quot;</span><span class="p">,</span> <span class="s2">&quot;India&quot;</span><span class="p">)</span> <span class="c1"># Just for fun</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>USA : pizza :: India : ?
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Analogy word</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>vada_pav</td>
      <td>0.554463</td>
    </tr>
    <tr>
      <th>1</th>
      <td>jalebi</td>
      <td>0.547090</td>
    </tr>
    <tr>
      <th>2</th>
      <td>idlis</td>
      <td>0.540039</td>
    </tr>
    <tr>
      <th>3</th>
      <td>pav_bhaji</td>
      <td>0.526046</td>
    </tr>
    <tr>
      <th>4</th>
      <td>dosas</td>
      <td>0.521772</td>
    </tr>
    <tr>
      <th>5</th>
      <td>samosa</td>
      <td>0.520700</td>
    </tr>
    <tr>
      <th>6</th>
      <td>idli</td>
      <td>0.516858</td>
    </tr>
    <tr>
      <th>7</th>
      <td>pizzas</td>
      <td>0.516199</td>
    </tr>
    <tr>
      <th>8</th>
      <td>tiffin</td>
      <td>0.514347</td>
    </tr>
    <tr>
      <th>9</th>
      <td>chaat</td>
      <td>0.508534</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>So you can imagine these models being useful in many meaning-related tasks.</p>
<p><img alt="" src="../_images/word2vec-country-capitals.png" /></p>
<p>(Credit: Mikolov et al. 2013)</p>
<p><strong>Examples of semantic and syntactic relationships</strong></p>
<a class="reference internal image-reference" href="../_images/word_analogies2.png"><img alt="../_images/word_analogies2.png" src="../_images/word_analogies2.png" style="width: 800px; height: 800px;" /></a>
<p>(Credit: Mikolov 2013)</p>
</section>
<section id="implicit-biases-and-stereotypes-in-word-embeddings">
<h3>4.5 Implicit biases and stereotypes in word embeddings<a class="headerlink" href="#implicit-biases-and-stereotypes-in-word-embeddings" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analogy</span><span class="p">(</span><span class="s2">&quot;man&quot;</span><span class="p">,</span> <span class="s2">&quot;computer_programmer&quot;</span><span class="p">,</span> <span class="s2">&quot;woman&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>man : computer_programmer :: woman : ?
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Analogy word</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>homemaker</td>
      <td>0.562712</td>
    </tr>
    <tr>
      <th>1</th>
      <td>housewife</td>
      <td>0.510505</td>
    </tr>
    <tr>
      <th>2</th>
      <td>graphic_designer</td>
      <td>0.505180</td>
    </tr>
    <tr>
      <th>3</th>
      <td>schoolteacher</td>
      <td>0.497949</td>
    </tr>
    <tr>
      <th>4</th>
      <td>businesswoman</td>
      <td>0.493489</td>
    </tr>
    <tr>
      <th>5</th>
      <td>paralegal</td>
      <td>0.492551</td>
    </tr>
    <tr>
      <th>6</th>
      <td>registered_nurse</td>
      <td>0.490797</td>
    </tr>
    <tr>
      <th>7</th>
      <td>saleswoman</td>
      <td>0.488163</td>
    </tr>
    <tr>
      <th>8</th>
      <td>electrical_engineer</td>
      <td>0.479773</td>
    </tr>
    <tr>
      <th>9</th>
      <td>mechanical_engineer</td>
      <td>0.475540</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><img alt="" src="../_images/eva-srsly.png" /></p>
<ul class="simple">
<li><p>Embeddings reflect gender stereotypes present in broader society.</p></li>
<li><p>They may also amplify these stereotypes because of their widespread usage.</p></li>
<li><p>See the paper <a class="reference external" href="http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf">Man is to Computer Programmer as Woman is to …</a>.</p></li>
</ul>
<p>Most of the modern embeddings are de-biased for some obvious biases.</p>
</section>
<section id="other-popular-methods-to-get-embeddings">
<h3>4.6 Other popular methods to get embeddings<a class="headerlink" href="#other-popular-methods-to-get-embeddings" title="Permalink to this heading">#</a></h3>
</section>
<section id="fasttext">
<h3><a class="reference external" href="https://fasttext.cc/">fastText</a><a class="headerlink" href="#fasttext" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>NLP library by Facebook research</p></li>
<li><p>Includes an algorithm which is an extension to word2vec</p></li>
<li><p>Helps deal with unknown words elegantly</p></li>
<li><p>Breaks words into several n-gram subwords</p></li>
<li><p>Example: trigram sub-words for <em>berry</em> are <em>ber</em>, <em>err</em>, <em>rry</em></p></li>
<li><p>Embedding(<em>berry</em>) = embedding(<em>ber</em>) + embedding(<em>err</em>) + embedding(rry)</p></li>
</ul>
</section>
<section id="optional-glove-global-vectors-for-word-representation">
<h3>(Optional) <a class="reference external" href="https://nlp.stanford.edu/projects/glove/">GloVe: Global Vectors for Word Representation</a><a class="headerlink" href="#optional-glove-global-vectors-for-word-representation" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Starts with the co-occurrence matrix</p>
<ul>
<li><p>Co-occurrence can be interpreted as an indicator of semantic proximity of words</p></li>
</ul>
</li>
<li><p>Takes advantage of global count statistics</p></li>
<li><p>Predicts co-occurrence ratios</p></li>
<li><p>Loss based on word frequency</p></li>
</ul>
<p><br><br><br><br></p>
</section>
</section>
<section id="id2">
<h2>❓❓ Questions for you<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<section id="exercise-5-2-select-all-of-the-following-statements-which-are-true-iclicker">
<h3>Exercise 5.2 Select all of the following statements which are <strong>True</strong> (iClicker)<a class="headerlink" href="#exercise-5-2-select-all-of-the-following-statements-which-are-true-iclicker" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>(A) Suppose you learn word embeddings for a vocabulary of 20,000 words using word2vec. Then each dense word embedding associated with a word is of size 20,000 to make sure that we capture the full range of meaning of that word.</p></li>
<li><p>(B) If you try to get word vector for a word outside the vocabulary of your word2vec model, it will throw an error.</p></li>
<li><p>(C) A model trained with fastText is likely to contain representation for words even when they are not in the vocabulary.</p></li>
<li><p>(D) Suppose I have a HUGE corpus of biomedical text, which contains many domain-specific words and abbreviations. It makes sense to train our own embeddings to get word representations of the words in the corpus rather than using pre-trained Google News embeddings.</p></li>
<li><p>(E) Suppose my corpus gets updated very often, and the new text tends to contain many unknown words. It makes sense to either train fastText or use pre-trained embeddings trained using fastText.</p></li>
</ul>
<p><br><br><br><br></p>
</section>
</section>
<section id="final-comments-summary-and-reflection">
<h2>Final comments, summary, and reflection<a class="headerlink" href="#final-comments-summary-and-reflection" title="Permalink to this heading">#</a></h2>
<section id="word-embeddings">
<h3>Word embeddings<a class="headerlink" href="#word-embeddings" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Word embeddings give a representation of individual words in a vector space so that</p>
<ul>
<li><p>Distance between words in this vector space indicate the relationship between them.</p></li>
</ul>
</li>
<li><p>Word representations</p>
<ul>
<li><p>One-hot encoding</p>
<ul>
<li><p>not able to capture similarities between words</p></li>
</ul>
</li>
<li><p>Term-term co-occurrence matrix</p>
<ul>
<li><p>long and sparse representations</p></li>
</ul>
</li>
<li><p>word2vec</p>
<ul>
<li><p>short and dense representations</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="id3">
<h3>word2vec<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>word2vec is a recent alternative to LSA.</p></li>
<li><p>One of the most widely used and influential algorithms in the last decade.</p></li>
<li><p>Skipgram model predicts surrounding words (context words) given a target word.</p></li>
<li><p>We are not interested in the prediction task itself but we are interested in the learned weights which we use as word embeddings.</p></li>
<li><p>Freely available code and pre-trained models.</p></li>
<li><p>Generally do not train these models yourself. It’s very likely that there are pre-trained embedddings available for the domain of your interest.</p></li>
</ul>
</section>
<section id="id4">
<h3>Pre-trained embeddings<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Available for many different languages in a variety of domains.</p></li>
<li><p>Finally beware of biases and stereotypes encoded in these word embeddings!</p></li>
</ul>
</section>
</section>
<section id="resources">
<h2>Resources<a class="headerlink" href="#resources" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://projector.tensorflow.org/">Embedding Projector</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=25nC0n9ERq4">Word embedding workshop by Rachel Thomas</a></p></li>
<li><p><a class="reference external" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed representations of words and phrases and their compositionality</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1301.3781.pdf">Efficient estimation of word representations in vector space</a></p></li>
<li><p><a class="reference external" href="https://www.aclweb.org/anthology/N13-1090">Linguistic regularities in continuous space word representations</a></p></li>
<li><p><a class="reference external" href="http://aclweb.org/anthology/Q17-1010">Enriching Word Vectors with Subword Information</a></p></li>
</ul>
</section>
<section id="fun-tools">
<h2>Fun tools<a class="headerlink" href="#fun-tools" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://ronxin.github.io/wevi/">wevi: word embedding visual inspector</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-563-py"
        },
        kernelOptions: {
            name: "conda-env-563-py",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-563-py'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="04_More-PCA-LSA-NMF.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 4: More PCA, LSA, and NMF</p>
      </div>
    </a>
    <a class="right-next"
       href="06_more-word2vec-tsne.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 6: Using word embeddings, manifold learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-plan-imports-los">Lecture plan, imports, LOs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-plan">Lecture plan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-outcomes">Learning outcomes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation-and-context">1. Motivation and context</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activity-context-and-word-meaning">1.1 Activity: Context and word meaning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word-representations-intro">Word representations: intro</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-representations">2. Word representations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activity-brainstorm-ways-to-represent-words-2-mins">Activity:  Brainstorm ways to represent words (~2 mins)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simplest-representation-one-hot-representation-of-words">2.1 Simplest representation: One-hot representation of words</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#term-term-co-occurrence-matrix">2.2 Term-term co-occurrence matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-word-vectors-and-similarity">Visualizing word vectors and similarity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Visualizing word vectors and similarity</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dense-representations">3. Dense representations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-can-we-do-with-these-word-representations">3.1 What can we do with these word representations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-dense-representations">3.2 Creating dense representations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-dense-embeddings-with-lsa">3.2.1 (Optional) Dense embeddings with LSA</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec">3.2.2 word2vec</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simple-neural-network-architecture-source">A simple neural network architecture (Source)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram-objective">Skip-gram objective</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#questions-for-you">❓❓ Questions for you</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-1-select-all-of-the-following-statements-which-are-true-iclicker">Exercise 5.1 Select all of the following statements which are <strong>True</strong> (iClicker)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-word2vec">4. More word2vec</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram-demo-with-toy-data">4.1 Skip-gram demo with toy data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-word2vec-embeddings">4.2 Training word2vec embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-trained-embeddings">4.3 Pre-trained embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#success-of-word2vec">4.4 Success of word2vec</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implicit-biases-and-stereotypes-in-word-embeddings">4.5 Implicit biases and stereotypes in word embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-popular-methods-to-get-embeddings">4.6 Other popular methods to get embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fasttext">fastText</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-glove-global-vectors-for-word-representation">(Optional) GloVe: Global Vectors for Word Representation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">❓❓ Questions for you</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-2-select-all-of-the-following-statements-which-are-true-iclicker">Exercise 5.2 Select all of the following statements which are <strong>True</strong> (iClicker)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-comments-summary-and-reflection">Final comments, summary, and reflection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word-embeddings">Word embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">word2vec</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Pre-trained embeddings</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resources">Resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fun-tools">Fun tools</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Varada Kolhatkar
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>